import streamlit as st
import google.generativeai as genai
import pandas as pd
import time
import os
import re
import requests
import hashlib
import hmac
import base64
import concurrent.futures
import io 
import zipfile              
import markdown  # ğŸš€ æ–°å¢ï¼šç”¨äºå°†æ–‡æœ¬æ¸²æŸ“ä¸ºæç¾ç½‘é¡µæ’ç‰ˆ

# ==========================================
# 0. é¡µé¢ä¸ Secrets é…ç½®
# ==========================================
st.set_page_config(page_title="LxU æµ‹å“å·¥ä½œæµ (ç»ˆæç¨³å®šç‰ˆ)", layout="wide")

GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
NAVER_API_KEY = st.secrets.get("API_KEY")
NAVER_SECRET_KEY = st.secrets.get("SECRET_KEY")
NAVER_CUSTOMER_ID = st.secrets.get("CUSTOMER_ID")

if not all([GEMINI_API_KEY, NAVER_API_KEY, NAVER_SECRET_KEY, NAVER_CUSTOMER_ID]):
    st.error("âš ï¸ ç¼ºå°‘ API å¯†é’¥ï¼è¯·ç¡®ä¿ Secrets ä¸­é…ç½®äº†æ‰€æœ‰å¿…éœ€çš„ Keyã€‚")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
SECRET_KEY_BYTES = NAVER_SECRET_KEY.encode("utf-8")
NAVER_API_URL = "https://api.searchad.naver.com/keywordstool"

# ==========================================
# 1. æ ¸å¿ƒæŒ‡ä»¤
# ==========================================
PROMPT_STEP_1 = """
ä½ æ˜¯ä¸€ä¸ªåœ¨éŸ©å›½å¸‚åœºæ‹¥æœ‰å¤šå¹´å®æˆ˜ç»éªŒçš„ç”µå•†è¿è¥ä¸“å®¶ï¼Œç†Ÿæ‚‰ Coupang ä¸ Naver SmartStore çš„æœç´¢æœºåˆ¶å’Œç”¨æˆ·ç‚¹å‡»è¡Œä¸ºã€‚ä½ çš„æ•´ä¸ªè¿è¥å›¢é˜Ÿéƒ½åœ¨ä¸­å›½ï¼Œæ‰€ä»¥ä½ å¿…é¡»éµå®ˆä»¥ä¸‹æå…¶ä¸¥æ ¼çš„ã€è¯­è¨€è¾“å‡ºéš”ç¦»è§„èŒƒã€‘ï¼š
1. æ‰€æœ‰çš„â€œåˆ†æè¿‡ç¨‹â€ã€â€œç­–ç•¥è§£é‡Šâ€ç­‰æè¿°æ€§è´¨çš„æ–‡å­—ï¼Œå¿…é¡» 100% ä½¿ç”¨ã€ç®€ä½“ä¸­æ–‡ã€‘ï¼ç»å¯¹ç¦æ­¢ä½¿ç”¨éŸ©æ–‡è§£é‡Šï¼
2. åªæœ‰â€œéŸ©æ–‡å…³é”®è¯æœ¬èº«â€ã€â€œéŸ©è¯­æ ‡é¢˜â€å’Œâ€œå•†å“å¥½è¯„çš„éŸ©æ–‡åŸæ–‡â€å…è®¸å‡ºç°éŸ©æ–‡ï¼Œä¸”å¿…é¡»å…¨éƒ¨é™„å¸¦å¯¹åº”çš„ã€ä¸­æ–‡ç¿»è¯‘ã€‘ã€‚

--- æ ¸å¿ƒä»»åŠ¡ ---
åŸºäºæˆ‘æä¾›çš„å•†å“å›¾ç‰‡ï¼Œç”Ÿæˆèƒ½å¤Ÿæé«˜ç‚¹å‡»ç‡ã€è¯­ä¹‰è‡ªç„¶ã€æœ¬åœŸåŒ–è¡¨è¾¾å¼ºã€çªå‡ºå–ç‚¹çš„å•†å“æ ‡é¢˜ï¼ŒåŒæ—¶å…¼é¡¾æœç´¢åŒ¹é…ã€‚

ã€å“ç‰Œä¸é€šç”¨è§„åˆ™ã€‘ï¼š
- å“ç‰Œåå…¨éƒ¨é»˜è®¤å›ºå®šä¸ºï¼šLxU
- ä¸¥ç¦ä½¿ç”¨å¤¸å¼ è¥é”€è¯ï¼ˆå¦‚ ìµœê³ , 1ìœ„, ì™„ë²½ ç­‰ï¼‰ã€‚
- æ ‡é¢˜ä¸­ã€ç»å¯¹ä¸è¦ä½¿ç”¨ä»»ä½•æ ‡ç‚¹ç¬¦å·ã€‘ï¼Œè¯è¯­ä¹‹é—´ç”¨ç©ºæ ¼è‡ªç„¶éš”å¼€å³å¯ã€‚
- æ ‡é¢˜å¿…é¡»ã€è¯­å¥é€šé¡ºè‡ªç„¶ã€‘ï¼Œç¬¦åˆçœŸå®éŸ©å›½æœ¬åœŸä¹°å®¶çš„æœç´¢å’Œé˜…è¯»ä¹ æƒ¯ã€‚

ã€ğŸ’¡ æåº¦é‡è¦æ’ç‰ˆè¦æ±‚ï¼šä¸€é”®å¤åˆ¶åŠŸèƒ½ã€‘ï¼š
ä½ ç”Ÿæˆçš„â€œçº¯éŸ©æ–‡é€—å·éš”å¼€çš„åå°å…³é”®è¯â€ä»¥åŠâ€œçº¯éŸ©æ–‡è¯„ä»·â€ï¼Œå¿…é¡»å•ç‹¬æ”¾åœ¨ Markdown ä»£ç å—é‡Œé¢ï¼
**è­¦å‘Šï¼šä»£ç å—å¼€å¤´åªå…è®¸å†™ä¸‰ä¸ªåå¼•å· ``` ï¼Œç»å¯¹ä¸å…è®¸å‡ºç° ```text æˆ–ä»»ä½•å­—æ¯ï¼ä»£ç å—å†…åªæœ‰çº¯éŸ©æ–‡ï¼ˆå¦‚æœæ˜¯å…³é”®è¯åŠ é€—å·ï¼‰ï¼Œä¸å…è®¸æœ‰å…¶ä»–å¤šä½™è§£é‡Šï¼**

ç¬¬ä¸€éƒ¨åˆ†ï¼šCoupang ä¸“å±ä¼˜åŒ– (åè½¬åŒ–ä¸æ¸…æ™°è¡¨è¾¾)
1. æ ‡é¢˜å…¬å¼ï¼šLxU + æ ¸å¿ƒå–ç‚¹ + å…³é”®è§„æ ¼æˆ–å±æ€§ + ä½¿ç”¨åœºæ™¯æˆ–è§£å†³é—®é¢˜ç‚¹ã€‚æ ¸å¿ƒè¯å¿…é¡»æ”¾å‰é¢ã€‚
-> è¾“å‡ºå¸¦ä¸­æ–‡ç¿»è¯‘çš„æ ‡é¢˜ï¼ˆéŸ©æ–‡æ ‡é¢˜åŠ¡å¿…æ”¾åœ¨ä¸Šè¿°è¦æ±‚çš„ä»£ç å—é‡Œï¼‰ã€‚
2. æŒ–æ˜ 20 ä¸ª Coupang åå°ç²¾å‡†å…³é”®è¯ï¼ˆ2~20å­—ç¬¦ï¼‰ã€‚
-> å¿…é¡»ä»¥ Markdown è¡¨æ ¼è¾“å‡ºï¼šã€åºå· | CoupangéŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | çº¯ä¸­æ–‡ç­–ç•¥è§£é‡Šã€‘ã€‚
-> è¡¨æ ¼ä¸‹æ–¹ï¼Œå•ç‹¬æŠŠè¿™20ä¸ªçº¯éŸ©æ–‡è¯ç”¨é€—å·éš”å¼€ï¼Œå¹¶åŠ¡å¿…æ”¾åœ¨ä¸Šè¿°è¦æ±‚çš„ä»£ç å—é‡Œè¾“å‡ºã€‚

ç¬¬äºŒéƒ¨åˆ†ï¼šNaver ä¸“å±ä¼˜åŒ– (åæœç´¢è¦†ç›–ä¸æ›å…‰)
1. æ ‡é¢˜è§„åˆ™ï¼šLxU + æ ¸å¿ƒè¯ + ä¿®é¥°è¯ä¸é•¿å°¾è¯ï¼ŒåŠ å…¥æ›´å¤šç”¨æˆ·æœç´¢è¡¨è¾¾ã€‚
-> è¾“å‡ºå¸¦ä¸­æ–‡ç¿»è¯‘çš„æ ‡é¢˜ï¼ˆéŸ©æ–‡æ ‡é¢˜åŠ¡å¿…æ”¾åœ¨ä»£ç å—é‡Œï¼‰ã€‚
2. æŒ–æ˜ 20 ä¸ª Naver åå°æ‰©å±•å…³é”®è¯ï¼ˆåæœç´¢æ‰©å±•ï¼‰ã€‚
-> å¿…é¡»ä»¥ Markdown è¡¨æ ¼è¾“å‡ºï¼šã€åºå· | NaveréŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | çº¯ä¸­æ–‡ç­–ç•¥è§£é‡Šã€‘ã€‚
-> è¡¨æ ¼ä¸‹æ–¹ï¼Œå•ç‹¬æŠŠè¿™20ä¸ªçº¯éŸ©æ–‡è¯ç”¨é€—å·éš”å¼€ï¼Œå¹¶åŠ¡å¿…æ”¾åœ¨ä»£ç å—é‡Œè¾“å‡ºã€‚

ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ‰¾ç²¾å‡†é•¿å°¾è¯åšä»˜è´¹æ¨å¹¿
å¹¿å‘Šç»„ä¸€ä¸ºã€æ ¸å¿ƒå‡ºå•è¯ã€‘ï¼Œå¹¿å‘Šç»„äºŒä¸ºã€ç²¾å‡†é•¿å°¾å…³é”®è¯ã€‘ï¼Œå¹¿å‘Šç»„ä¸‰ä¸ºã€é•¿å°¾æ¡æ¼ç»„ã€‘ã€‚
è¾“å‡ºæ ¼å¼ä¸º Markdown è¡¨æ ¼ï¼šã€åºå· | å¹¿å‘Šç»„åˆ†ç±» | éŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | ä¸­æ–‡ç­–ç•¥è§£é‡Š | é¢„ä¼°æµé‡ | ç›¸å…³æ€§è¯„åˆ†(1-5)ã€‘ã€‚

ç¬¬å››éƒ¨åˆ†ï¼šæä¾›ä¸€ä¸ªäº§å“éŸ©è¯­åç§°ç”¨äºå†…éƒ¨ç®¡ç†ï¼ˆé™„å¸¦ä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚

ç¬¬äº”éƒ¨åˆ†ï¼šæŒ‰ç…§äº§å“å–ç‚¹æ’°å†™5æ¡å•†å“éŸ©æ–‡å¥½è¯„ã€‚
1. å…ˆä»¥ Markdown è¡¨æ ¼å½¢å¼æ’åˆ—ï¼šã€åºå· | éŸ©æ–‡è¯„ä»·åŸæ–‡ | çº¯ä¸­æ–‡ç¿»è¯‘ | ä¹°å®¶ç—›ç‚¹åˆ†æã€‘ã€‚
2. è¡¨æ ¼ä¸‹æ–¹ï¼Œå°†è¿™5æ¡çº¯éŸ©æ–‡è¯„ä»·åŸæ–‡æŒ‰è¡Œéš”å¼€ï¼Œå•ç‹¬æ”¾åœ¨ ``` ä»£ç å—ä¸­è¾“å‡ºï¼Œæ–¹ä¾¿ä¸€é”®å¤åˆ¶ã€‚

ç¬¬å…­éƒ¨åˆ†ï¼šAI ä¸»å›¾ç”Ÿæˆå»ºè®®ï¼šåŸºäºåœºæ™¯è¯ç”¨çº¯ä¸­æ–‡å»ºè®®èƒŒæ™¯å’Œæ„å›¾ã€‚

ã€ç¨‹åºè¯»å–ä¸“å±æŒ‡ä»¤ - æåº¦é‡è¦ã€‘ï¼š
å°†ä¸Šè¿°æ‰€æœ‰ç”Ÿæˆçš„ã€éŸ©æ–‡å…³é”®è¯ã€‘è¿›è¡Œå…¨é¢å»é‡æ±‡æ€»ï¼Œå•åˆ—æ¨ªå‘è¾“å‡ºï¼Œå¹¶ä¸”**å¿…é¡»æ”¾åœ¨ä»¥ä¸‹ä¸¤ä¸ªæ ‡è®°ä¹‹é—´**ï¼
âš ï¸ è­¦å‘Šï¼šè¿™é‡Œçš„å…³é”®è¯ä¹‹é—´ã€å¿…é¡»ä½¿ç”¨è‹±æ–‡é€—å· (,) éš”å¼€ã€‘ï¼ç»å¯¹ä¸å…è®¸åªç”¨ç©ºæ ¼è¿åœ¨ä¸€èµ·ï¼
[LXU_KEYWORDS_START]
å…³é”®è¯1,å…³é”®è¯2,å…³é”®è¯3
[LXU_KEYWORDS_END]
"""

PROMPT_STEP_3 = """
ã€ä»¥ä¸‹æ˜¯å¸‚åœºæ ¸å¿ƒæœç´¢è¯åŠæ‹“å±•è¯çœŸå®æµé‡æ•°æ®ã€‘ï¼š
{market_data}

=======================================================
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´å®æˆ˜ç»éªŒçš„éŸ©å›½ Coupang è·¨å¢ƒç”µå•†é«˜çº§å¹¿å‘Šæ“ç›˜æ‰‹ã€‚æ•´ä¸ªå›¢é˜Ÿéƒ½åœ¨ä¸­å›½ï¼Œé™¤éŸ©æ–‡å…³é”®è¯å¤–ï¼Œæ‰€æœ‰è§£é‡Šåˆ†æå¿…é¡»ç”¨çº¯ä¸­æ–‡è¾“å‡ºã€‚ç»å¯¹ä¸è¦å‡ºç° LxU çš„å“ç‰Œè¯ï¼
è¯·ä½ åŸºäºæˆ‘æä¾›çš„ã€äº§å“åŸå›¾ã€‘ï¼Œæ·±åº¦åˆ†æä¸Šæ–¹çš„ã€å¸‚åœºæµé‡æ•°æ®ã€‘ï¼Œä¸¥æ ¼å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

ç¬¬ä¸€æ­¥ï¼šäº§å“å…¨ç»´åº¦æ·±åº¦è§£æä¸æ’é›·ï¼ˆå¿…é¡»çº¯ä¸­æ–‡ï¼‰
ä¸ºäº†ç¡®ä¿ä½ å¯¹äº§å“çš„ç†è§£ç»å¯¹å‡†ç¡®ï¼Œå¹¶ä¸ºåç»­å¹¿å‘Šè¯æ‰“åˆ†æä¾›äº‹å®ä¾æ®ï¼Œè¯·åœ¨æŠ¥å‘Šæœ€å¼€å¤´æ˜ç¡®è¾“å‡ºä»¥ä¸‹è§£æï¼š
1. äº§å“æ ¸å¿ƒå±æ€§ï¼šç²¾å‡†æå–è¯¥äº§å“çš„çœŸå®æè´¨ã€å¤–è§‚å½¢æ€ã€æ ¸å¿ƒå–ç‚¹åŠé€‚ç”¨åœºæ™¯ã€‚
2. ä¹°å®¶ç—›ç‚¹æŒ–æ˜ï¼šæ·±åº¦åˆ†æç›®æ ‡äººç¾¤è´­ä¹°è¯¥äº§å“æ˜¯ä¸ºäº†è§£å†³ä»€ä¹ˆç—›ç‚¹ï¼Ÿ
3. ç»å¯¹çº¢çº¿ï¼ˆæ’é›·æ ‡å‡†ï¼‰ï¼šæ˜ç¡®åˆ—å‡ºå“ªäº›å±æ€§ã€æè´¨æˆ–åœºæ™¯æ˜¯ä¸æœ¬äº§å“**ç»å¯¹å†²çª**çš„ï¼ˆå¦‚äº§å“æ˜¯å¡‘æ–™ï¼Œçº¢çº¿å°±æ˜¯é‡‘å±ï¼›æˆ–è€…ä¸ç›¸å…³çš„åŠŸèƒ½è¯ç­‰ï¼‰ï¼Œå¹¶åœ¨åç»­é€‰è¯ä¸­åšå†³å±è”½å®ƒä»¬ï¼

ç¬¬äºŒæ­¥ï¼šåŸºäºç¬¬ä¸€æ­¥åŸè¯çš„â€œæ·±åŒ–åˆ†ç±»ä¸æå–â€ï¼ˆæåº¦é‡è¦ï¼Œç»å¯¹ä¸è®¸å·æ‡’ï¼ï¼‰
ä¸Šæ–¹çš„æµé‡æ•°æ®ä¸­ï¼ŒåŒ…å«äº†æˆ‘ä»¬åœ¨æœ€åˆæœŸä¸ºä½ æä¾›çš„ã€ç›®æ ‡åŸè¯ã€‘ï¼ˆä¹Ÿå°±æ˜¯ä½ è®¤ä¸ºæœ€ç¬¦åˆå›¾ç‰‡çš„è¯ï¼‰ä»¥åŠ Naver æ‹“å±•å‡ºçš„å¤§è¯ã€‚
ä½ **å¿…é¡»ä»¥ç¬¬ä¸€æ­¥æç‚¼çš„ã€ç›®æ ‡åŸè¯ã€‘ä¸ºæ ¸å¿ƒåŸºçŸ³è¿›è¡Œæ·±åŒ–**ï¼Œç»“åˆé«˜è´¨é‡çš„ Naver æ‹“å±•è¯ï¼ŒæŒ‘é€‰å‡º 40-60 ä¸ªæœ€å…·è½¬åŒ–ä»·å€¼çš„è¯ã€‚
ä½ **å¿…é¡»ã€ç»å¯¹**è¦æŠŠè¿™äº›è¯åˆ†é…åˆ°ä»¥ä¸‹ä¸‰ä¸ªã€æ˜ç¡®çš„å¹¿å‘Šç»„ã€‘ä¸­ï¼Œä»»ä½•ä¸€ç»„éƒ½ç»å¯¹ä¸å…è®¸ä¸ºç©ºï¼
- ã€æ ¸å¿ƒå‡ºå•è¯ã€‘(1åˆ†)
- ã€ç²¾å‡†é•¿å°¾è¯ã€‘(2åˆ†)
- ã€æ¡æ¼ä¸ç—›ç‚¹ç»„ã€‘(3åˆ†)

ç¬¬ä¸‰æ­¥ï¼šé«˜ä»·å€¼ä»˜è´¹å¹¿å‘ŠæŠ•æ”¾ç­–ç•¥è¡¨ï¼ˆç›´æ¥å¡«å†™çœŸå®æ•°æ®ï¼Œç»å¯¹ä¸è¦è¾“å‡ºçœç•¥å·ï¼‰
ã€å¼ºåˆ¶è¡¨æ ¼æ ¼å¼ã€‘ï¼š
è¯·ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹ Markdown è¡¨å¤´ç»“æ„è¾“å‡ºè¡¨æ ¼ã€‚
**è­¦å‘Šï¼šä¸è¦è¾“å‡ºä»»ä½•çœç•¥å·â€œ...â€æˆ–å¹²æ‰°è™šçº¿ï¼Œè¯·ç›´æ¥å°†æŒ‘é€‰å‡ºçš„çœŸå®å…³é”®è¯æ•°æ®ä¸€è¡Œä¸€è¡Œå¡«æ»¡è¡¨æ ¼ï¼**
å¿…é¡»æŒ‰ä¸‰å¤§åˆ†ç±»çš„é¡ºåºå±•ç¤ºï¼ˆæ ¸å¿ƒå‡ºå•è¯ â¡ï¸ ç²¾å‡†é•¿å°¾è¯ â¡ï¸ æ¡æ¼ä¸ç—›ç‚¹ç»„ï¼‰ï¼Œä¸”æ¯ä¸ªåˆ†ç±»å†…éƒ¨æŒ‰â€œæœˆæ€»æœç´¢é‡â€é™åºæ’åˆ—ï¼

| åºå· | å¹¿å‘Šç»„åˆ†ç±» | ç›¸å…³æ€§è¯„åˆ† | éŸ©æ–‡å…³é”®è¯ | æœˆæ€»æœç´¢é‡ | ä¸­æ–‡ç¿»è¯‘ | ç«äº‰åº¦ | æ¨èç­–ç•¥ä¸è¯´æ˜ |
|---|---|---|---|---|---|---|---|

ç¬¬å››æ­¥ï¼šå¦å®šå…³é”®è¯åˆ—è¡¨ (Negative Keywords)
- å»ºè®®å±è”½çš„è¯ï¼š[ç”¨é€—å·éš”å¼€ï¼Œä»æ•°æ®ä¸­æŒ‘å‡ºé‚£äº›è§¦ç¢°çº¢çº¿ã€æ— è´­ç‰©æ„å›¾çš„åƒåœ¾æ‹“å±•è¯ã€‚å¿…é¡»è‡³å°‘åˆ—å‡º 10 ä¸ªçœŸå®çš„è¿‡æ»¤è¯ï¼]
- å±è”½åŸå› ï¼š[çº¯ä¸­æ–‡ç®€è¿°ç†ç”±]
"""

# ==========================================
# 2. å¼ºåŠ›å¼•æ“ï¼šå®‰å…¨ç”Ÿæˆä¸æ•°æ®æŠ“å–
# ==========================================

def safe_generate(model, contents, max_retries=3):
    for attempt in range(1, max_retries + 1):
        try:
            res = model.generate_content(contents)
            return res.text 
        except Exception as e:
            if attempt < max_retries:
                time.sleep(3) 
            else:
                return f"âŒ ä¸¥é‡é”™è¯¯ï¼šAPI è¿ç»­ {max_retries} æ¬¡æ— å“åº”æˆ–è¢«å®‰å…¨æ‹¦æˆªï¼Œæ— æ³•ç”Ÿæˆå†…å®¹ã€‚è¯¦æƒ…ï¼š{str(e)}"

def clean_for_api(keyword: str) -> str:
    return re.sub(r"\s+", "", keyword)

def make_signature(method: str, uri: str, timestamp: str) -> str:
    message = f"{timestamp}.{method}.{uri}".encode("utf-8")
    signature = hmac.new(SECRET_KEY_BYTES, message, hashlib.sha256).digest()
    return base64.b64encode(signature).decode("utf-8")

def normalize_count(raw):
    if isinstance(raw, int): return raw
    if isinstance(raw, str):
        s = raw.strip()
        if s.startswith("<"): return 5
        if s.startswith(">"):
            num = s[1:].strip()
            return int(num) if num.isdigit() else 0
        s = s.replace(",", "")
        if s.isdigit(): return int(s)
    return 0

def fetch_naver_data(main_keywords, pb, st_text):
    all_rows = []
    total = len(main_keywords)

    def fetch_single(mk):
        rows = []
        try:
            timestamp = str(int(time.time() * 1000))
            sig = make_signature("GET", "/keywordstool", timestamp)
            headers = {"X-Timestamp": timestamp, "X-API-KEY": NAVER_API_KEY, "X-Customer": NAVER_CUSTOMER_ID, "X-Signature": sig}
            res = requests.get(NAVER_API_URL, headers=headers, params={"hintKeywords": clean_for_api(mk), "showDetail": 1}, timeout=8)
            if res.status_code == 200:
                data = res.json()
                for item in data.get("keywordList", []): 
                    pc = normalize_count(item.get("monthlyPcQcCnt", 0))
                    mob = normalize_count(item.get("monthlyMobileQcCnt", 0))
                    rows.append({
                        "Naverå®é™…æœç´¢è¯": item.get("relKeyword", ""),
                        "æœˆæ€»æœç´¢é‡": pc + mob,
                        "ç«äº‰åº¦": item.get("compIdx", "-"),
                        "AIæº¯æº(åŸè¯)": mk
                    })
        except Exception:
            pass
        return rows

    completed = 0
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_mk = {executor.submit(fetch_single, mk): mk for mk in main_keywords}
        for future in concurrent.futures.as_completed(future_to_mk):
            mk = future_to_mk[future]
            completed += 1
            st_text.text(f"ğŸ“Š Naver æé€Ÿå¹¶å‘æ‹“è¯ä¸­ [{completed}/{total}]: {mk}")
            pb.progress(completed / total)
            try:
                all_rows.extend(future.result())
            except Exception:
                pass
            time.sleep(0.05) 
            
    df = pd.DataFrame(all_rows)
    if not df.empty:
        df = df.drop_duplicates(subset=["Naverå®é™…æœç´¢è¯"])
        
        seed_no_space = [str(k).replace(" ", "") for k in main_keywords]
        df['is_seed'] = df['Naverå®é™…æœç´¢è¯'].apply(lambda x: str(x).replace(" ", "") in seed_no_space)
        
        df.insert(1, 'è¯ç»„å±æ€§', df['is_seed'].apply(lambda x: 'ğŸ¯ ç›®æ ‡åŸè¯' if x else 'ğŸ’¡ è¡ç”Ÿæ‹“å±•è¯'))
        df = df.sort_values(by=["is_seed", "æœˆæ€»æœç´¢é‡"], ascending=[False, False])
        df = df.drop(columns=['is_seed'])
        
    return df

# ==========================================
# 3. ä¸» UI ä¸å…¨è‡ªåŠ¨å·¥ä½œæµ
# ==========================================
st.title("âš¡ LxU æµ‹å“ç­–ç•¥ç”Ÿæˆå™¨")
st.info("ğŸ’¡ æç¤ºï¼šè¿è¡Œä¸­å¦‚éœ€ç´§æ€¥ç»ˆæ­¢ï¼Œè¯·ç‚¹å‡»é¡µé¢å³ä¸Šè§’è‡ªå¸¦çš„åœ†å½¢ Stop æŒ‰é’®ã€‚")

if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç†äº‘ç«¯åƒåœ¾æ–‡ä»¶"):
    try:
        count = 0
        for f in genai.list_files():
            genai.delete_file(f.name)
            count += 1
        st.sidebar.success(f"æ¸…ç†äº† {count} ä¸ªç¼“å­˜æ–‡ä»¶ï¼")
    except Exception as e:
        st.sidebar.error(f"æ¸…ç†å¤±è´¥: {e}")

files = st.file_uploader("ğŸ“¥ è¯·ä¸Šä¼ äº§å“è¯¦æƒ…é¡µ (å¼ºçƒˆå»ºè®®æˆªå›¾ï¼Œä¿æŒåœ¨2MBå†…)", type=["pdf", "png", "jpg", "jpeg"], accept_multiple_files=True)

if files and st.button("ğŸš€ å¯åŠ¨å…¨è‡ªåŠ¨é—­ç¯", use_container_width=True):
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    master_zip_buffer = io.BytesIO()
    master_zip = zipfile.ZipFile(master_zip_buffer, 'w', zipfile.ZIP_DEFLATED)
    
    for file in files:
        st.divider()
        st.header(f"ğŸ“¦ æ­£åœ¨è‡ªåŠ¨å¤„ç†äº§å“ï¼š{file.name}")
        temp_path = f"temp_{file.name}"
        with open(temp_path, "wb") as f: f.write(file.getbuffer())
        
        res1_text = ""
        res3_text = ""
        kw_list = []
        market_csv = ""
        folder_name = os.path.splitext(file.name)[0]

        # ------------------ ç¬¬ä¸€æ­¥ï¼šè‡ªåŠ¨è¯†å›¾ä¸æå– ------------------
        with st.status("ğŸ” ç¬¬ä¸€æ­¥ï¼šAI è§†è§‰æç‚¼ä¸æœ¬åœ°åŒ–åˆ†æ...", expanded=True) as s1:
            try:
                gen_file = genai.upload_file(path=temp_path)
                while gen_file.state.name == "PROCESSING":
                    time.sleep(2)
                    gen_file = genai.get_file(gen_file.name)
                
                res1_text = safe_generate(model, [gen_file, PROMPT_STEP_1])
                
                if res1_text.startswith("âŒ"):
                    s1.update(label="âŒ ç¬¬ä¸€æ­¥ AI ç”Ÿæˆå½»åº•å¤±è´¥", state="error")
                    st.error(res1_text)
                    continue
                
                with st.expander("ğŸ‘‰ æŸ¥çœ‹ç¬¬ä¸€æ­¥å®Œæ•´æŠ¥å‘Š (å·²å¼ºåˆ¶çº¯ä¸­æ–‡éš”ç¦»)", expanded=False):
                    st.write(res1_text)
                
                match = re.search(r"\[LXU_KEYWORDS_START\](.*?)\[LXU_KEYWORDS_END\]", res1_text, re.DOTALL | re.IGNORECASE)
                if match:
                    raw_block = match.group(1)
                    raw_block = re.sub(r'[ï¼Œ\nã€|]', ',', raw_block) 
                    for kw in raw_block.split(','):
                        clean_word = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', kw).strip()
                        clean_word = re.sub(r'\s+', ' ', clean_word)
                        if clean_word and clean_word not in kw_list:
                            kw_list.append(clean_word)
                else:
                    tail_text = res1_text[-800:]
                    tail_text = re.sub(r'[ï¼Œ\nã€|]', ',', tail_text)
                    for kw in tail_text.split(','):
                        clean_word = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', kw).strip()
                        clean_word = re.sub(r'\s+', ' ', clean_word)
                        if clean_word and clean_word not in kw_list:
                            kw_list.append(clean_word)
                    kw_list = kw_list[:25]
                
                if kw_list:
                    s1.update(label=f"âœ… ç¬¬ä¸€æ­¥å®Œæˆï¼æˆåŠŸæˆªè· {len(kw_list)} ä¸ªçº¯æ­£éŸ©æ–‡è¯ç»„", state="complete")
                else:
                    s1.update(label="âŒ ç¬¬ä¸€æ­¥æå–å¤±è´¥ï¼Œæœªèƒ½æ‰¾åˆ°éŸ©æ–‡", state="error")
                    continue 
            except Exception as e:
                s1.update(label=f"âŒ æœ¬åœ°ç³»ç»Ÿé€»è¾‘é”™è¯¯: {e}", state="error")
                continue

        # ------------------ ç¬¬äºŒæ­¥ï¼šè‡ªåŠ¨è§¦å‘ Naver æµé‡å›æµ‹ ------------------
        with st.status("ğŸ“Š ç¬¬äºŒæ­¥ï¼šè¿æ¥ Naver è·å–çœŸå®æœç´¢æ•°æ® (è‡ªåŠ¨è·³è½¬)...", expanded=True) as s2:
            pb = st.progress(0)
            status_txt = st.empty()
            
            df_market = fetch_naver_data(kw_list, pb, status_txt)
            
            if not df_market.empty:
                st.dataframe(df_market)
                target_count = len(kw_list)
                derived_count = len(df_market)
                s2.update(label=f"âœ… ç¬¬äºŒæ­¥å®Œæˆï¼å·²è·å–æœ€æ–°éŸ©å›½å¸‚åœºå®¢è§‚æ•°æ® (ç›®æ ‡è¯ï¼š{target_count} ä¸ª â¡ï¸ è¡ç”Ÿè¯ï¼š{derived_count} ä¸ª)", state="complete")
            else:
                s2.update(label="âŒ ç¬¬äºŒæ­¥å¤±è´¥ï¼ŒNaver æœªè¿”å›æœ‰æ•ˆæ•°æ®", state="error")
                continue 

        # ------------------ ç¬¬ä¸‰æ­¥ï¼šè‡ªåŠ¨è§¦å‘ç»ˆæç­–ç•¥æ¨æ¼” ------------------
        with st.status("ğŸ§  ç¬¬ä¸‰æ­¥ï¼šä¸»å®¢è§‚æ•°æ®èåˆï¼Œç”Ÿæˆç»ˆæç­–ç•¥ (è‡ªåŠ¨è·³è½¬)...", expanded=True) as s3:
            try:
                seed_df = df_market[df_market["è¯ç»„å±æ€§"] == 'ğŸ¯ ç›®æ ‡åŸè¯']
                expanded_df = df_market[df_market["è¯ç»„å±æ€§"] == 'ğŸ’¡ è¡ç”Ÿæ‹“å±•è¯'].head(250)
                
                final_df = pd.concat([
                    seed_df.sort_values(by="æœˆæ€»æœç´¢é‡", ascending=False), 
                    expanded_df.sort_values(by="æœˆæ€»æœç´¢é‡", ascending=False)
                ]).drop_duplicates(subset=["Naverå®é™…æœç´¢è¯"])
                
                market_csv = final_df.to_csv(index=False)
                final_prompt = PROMPT_STEP_3.format(market_data=market_csv)
                
                res3_text = safe_generate(model, [gen_file, final_prompt])
                
                if res3_text.startswith("âŒ"):
                    s3.update(label="âŒ ç¬¬ä¸‰æ­¥ AI ç”Ÿæˆå½»åº•å¤±è´¥", state="error")
                    st.error(res3_text)
                else:
                    st.markdown("### ğŸ† LxU ç»ˆææµ‹å“ç­–ç•¥æŠ¥å‘Š")
                    st.success(res3_text)
                    s3.update(label="âœ… ç¬¬ä¸‰æ­¥å®Œæˆï¼ç»ˆææ’å…µå¸ƒé˜µå·²ç”Ÿæˆ", state="complete")
            except Exception as e:
                s3.update(label=f"âŒ ç¬¬ä¸‰æ­¥ç³»ç»Ÿé€»è¾‘é”™è¯¯: {e}", state="error")

        # ------------------ æ”¶å°¾ä¸æ–‡ä»¶ç”Ÿæˆ (ğŸš€ å‡çº§ä¸ºé«˜å®šç½‘é¡µç‰ˆæŠ¥å‘Š) ------------------
        os.remove(temp_path)
        try:
            genai.delete_file(gen_file.name)
        except:
            pass
            
        try:
            # === è§£æä¸æç‚¼ ===
            def parse_md_table(md_text, keyword):
                lines = md_text.split('\n')
                table_data = []
                is_table = False
                for line in lines:
                    line = line.strip()
                    if '|' in line and keyword in line:
                        is_table = True
                        table_data.append(line)
                        continue
                    if is_table:
                        if line.startswith('|') or line.endswith('|') or '|' in line:
                            if '---' not in line:
                                table_data.append(line)
                        else:
                            if len(line.strip()) > 0: 
                                break
                if not table_data:
                    return pd.DataFrame()
                parsed_rows = []
                for row in table_data:
                    cols = [col.strip() for col in row.split('|')]
                    if cols and not cols[0]: cols = cols[1:]   
                    if cols and not cols[-1]: cols = cols[:-1] 
                    parsed_rows.append(cols)
                if len(parsed_rows) > 1:
                    return pd.DataFrame(parsed_rows[1:], columns=parsed_rows[0])
                return pd.DataFrame()

            raw_titles = []
            for line in res1_text.split('\n'):
                line_clean = line.strip()
                if 'LxU' in line_clean and not any(x in line_clean for x in ['å…¬å¼', 'è§„åˆ™', 'å–ç‚¹', 'æ ¸å¿ƒè¯', 'ç¿»è¯‘', 'ä¸­æ–‡']):
                    clean_t = re.sub(r'```[a-zA-Z]*', '', line_clean)
                    clean_t = clean_t.strip('`*>- \t')
                    if clean_t.startswith('LxU') and clean_t not in raw_titles:
                        raw_titles.append(clean_t)
            
            coupang_title = raw_titles[0] if len(raw_titles) > 0 else "æœªæå–åˆ° Coupang æ ‡é¢˜ï¼Œè¯·æŸ¥é˜…å…¨æ™¯æŠ¥å‘Š"
            naver_title = raw_titles[1] if len(raw_titles) > 1 else "æœªæå–åˆ° Naver æ ‡é¢˜ï¼Œè¯·æŸ¥é˜…å…¨æ™¯æŠ¥å‘Š"

            kw_lines = []
            for line in res1_text.split('\n'):
                if ('ï¼Œ' in line or ',' in line) and '|' not in line and re.search(r'[ê°€-í£]', line):
                    if line.count(',') + line.count('ï¼Œ') >= 5: 
                        clean_kw = re.sub(r'```[a-zA-Z]*', '', line).strip()
                        clean_kw = clean_kw.strip('`').strip()
                        if clean_kw and clean_kw not in kw_lines:
                            kw_lines.append(clean_kw)
            
            coupang_kws = kw_lines[0] if len(kw_lines) > 0 else "æœªæå–åˆ° Coupang å…³é”®è¯ï¼Œè¯·æŸ¥é˜…å…¨æ™¯æŠ¥å‘Š"
            naver_kws = kw_lines[1] if len(kw_lines) > 1 else "æœªæå–åˆ° Naver å…³é”®è¯ï¼Œè¯·æŸ¥é˜…å…¨æ™¯æŠ¥å‘Š"

            df_sheet1 = pd.DataFrame({
                "ä¿¡æ¯ç»´åº¦": ["Coupang æ ‡é¢˜", "Coupang åå°å…³é”®è¯", "Naver æ ‡é¢˜", "Naver åå°å…³é”®è¯"],
                "æç‚¼å†…å®¹": [coupang_title, coupang_kws, naver_title, naver_kws]
            })

            df_comments = parse_md_table(res1_text, "éŸ©æ–‡è¯„ä»·åŸæ–‡")
            df_ads = parse_md_table(res3_text, "å¹¿å‘Šç»„åˆ†ç±»")

            # === å†™å…¥ Excel (å†…å­˜) ===
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='xlsxwriter') as writer:
                df_sheet1.to_excel(writer, index=False, sheet_name='ç™»å“æ ‡é¢˜')
                if not df_comments.empty:
                    df_comments.to_excel(writer, index=False, sheet_name='è¯„è®ºåŒºå†…å®¹')
                else:
                    pd.DataFrame([{"æç¤º": "æœªæ‰¾åˆ°è§„èŒƒçš„è¯„ä»·è¡¨æ ¼"}]).to_excel(writer, index=False, sheet_name='è¯„è®ºåŒºå†…å®¹')
                if not df_ads.empty:
                    df_ads.to_excel(writer, index=False, sheet_name='å¹¿å‘ŠæŠ•æ”¾å…³é”®è¯')
                else:
                    pd.DataFrame([{"æç¤º": "æœªæ‰¾åˆ°è§„èŒƒçš„å¹¿å‘Šç­–ç•¥è¡¨"}]).to_excel(writer, index=False, sheet_name='å¹¿å‘ŠæŠ•æ”¾å…³é”®è¯')
            excel_data = excel_buffer.getvalue()

            # === ğŸš€ å†™å…¥ç²¾ç¾ HTML ç½‘é¡µæŠ¥å‘Š (å®Œç¾æ›¿ä»£å®¹æ˜“ä¹±ç çš„ Word) ===
            css_style = """
            <style>
                body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Malgun Gothic", "Microsoft YaHei", sans-serif; padding: 40px; max-width: 1000px; margin: auto; line-height: 1.6; color: #333; background-color: #f4f6f9; }
                .container { background: #ffffff; padding: 40px; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05); }
                h1 { color: #1E3A8A; border-bottom: 2px solid #e2e8f0; padding-bottom: 10px; text-align: center; }
                h2 { color: #2563eb; margin-top: 30px; }
                h3 { color: #475569; }
                table { border-collapse: collapse; width: 100%; margin: 20px 0; font-size: 14px; border-radius: 8px; overflow: hidden; }
                th, td { border: 1px solid #e2e8f0; padding: 12px 15px; text-align: left; }
                th { background-color: #f8fafc; color: #1e293b; font-weight: 600; }
                tr:nth-child(even) { background-color: #f1f5f9; }
                pre { background-color: #1e293b; padding: 20px; border-radius: 8px; overflow-x: auto; color: #f8fafc; font-family: monospace; }
                code { background-color: #e2e8f0; padding: 2px 6px; border-radius: 4px; color: #b91c1c; font-size: 0.9em; }
                .print-btn { display: block; width: 200px; margin: 20px auto; padding: 10px; background-color: #2563eb; color: white; text-align: center; text-decoration: none; border-radius: 5px; font-weight: bold; cursor: pointer; border: none; }
                @media print { .print-btn { display: none; } body { background-color: white; } .container { box-shadow: none; padding: 0; } }
            </style>
            """
            
            # ä½¿ç”¨ markdown åº“å°† AI ç”Ÿæˆçš„æ–‡æœ¬è½¬æ¢ä¸º HTML è¡¨æ ¼å’Œæ’ç‰ˆ
            html_part1 = markdown.markdown(res1_text, extensions=['tables', 'fenced_code'])
            html_part3 = markdown.markdown(res3_text, extensions=['tables', 'fenced_code'])

            html_content = f"""
            <!DOCTYPE html>
            <html lang="zh-CN">
            <head>
                <meta charset="utf-8">
                <title>LxU æµ‹å“å…¨æ™¯æŠ¥å‘Š - {folder_name}</title>
                {css_style}
            </head>
            <body>
                <div class="container">
                    <button class="print-btn" onclick="window.print()">ğŸ–¨ï¸ ä¿å­˜ä¸ºé«˜è´¨é‡ PDF</button>
                    <h1>ğŸ“Š LxU æµ‹å“å…¨æ™¯æŠ¥å‘Š</h1>
                    <p style="text-align: center; color: #64748b;">æŠ¥å‘Šå½’å±äº§å“ï¼š{folder_name} | ç”Ÿæˆæ—¥æœŸï¼šè‡ªåŠ¨è®°å½•</p>
                    
                    <h2>ğŸ” ç¬¬ä¸€æ­¥ï¼šAI è§†è§‰æç‚¼ä¸æœ¬åœ°åŒ–åˆ†æ</h2>
                    {html_part1}
                    
                    <hr style="border: 1px dashed #cbd5e1; margin: 40px 0;">
                    
                    <h2>ğŸ§  ç¬¬ä¸‰æ­¥ï¼šäº§å“æ·±åº¦è§£æä¸ç»ˆæå¹¿å‘Šç­–ç•¥</h2>
                    {html_part3}
                </div>
            </body>
            </html>
            """
            
            # === å°†ç”Ÿæˆçš„ Excel å’Œ HTML ç½‘é¡µå†™å…¥ä¸» ZIP åŒ… ===
            master_zip.writestr(f"{folder_name}/LxU_æ•°æ®è¡¨_{folder_name}.xlsx", excel_data)
            # å­˜ä¸º .html åç¼€
            master_zip.writestr(f"{folder_name}/LxU_è§†è§‰æŠ¥å‘Š_{folder_name}.html", html_content.encode('utf-8'))
            
            st.success(f"ğŸ“¦ ã€{file.name}ã€‘ å¤„ç†å®Œæ¯•ï¼å·²æ‰“åŒ…å­˜å…¥å†…å­˜ã€‚")
            
        except Exception as e:
            st.error(f"å¤„ç† {file.name} æ„å»ºå¯¼å‡ºæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # ==========================================
    # 4. å¾ªç¯ç»“æŸåï¼Œæä¾›ç»Ÿä¸€å¤§å‹ç¼©åŒ…ä¸‹è½½
    # ==========================================
    master_zip.close() # å…³é—­ZIPå†™å…¥æµ
    if files:
        st.divider()
        st.markdown("### ğŸ‰ å…¨éƒ¨äº§å“å¤„ç†å®Œæˆï¼")
        st.download_button(
            label=f"ğŸ“¥ ä¸€é”®ä¸‹è½½å…¨éƒ¨ç»“æœ (ZIP å‹ç¼©åŒ…)", 
            data=master_zip_buffer.getvalue(), 
            file_name="LxU_æ‰¹é‡æµ‹å“ç»“æœåˆé›†.zip",
            mime="application/zip",
            use_container_width=True
        )

