import streamlit as st
import google.generativeai as genai
import pandas as pd
import time
import os
import re
import requests
import hashlib
import hmac
import base64

# ==========================================
# 0. é¡µé¢ä¸ Secrets é…ç½®
# ==========================================
st.set_page_config(page_title="LxU æµ‹å“å·¥ä½œæµ (ç»ˆæä¸­æ–‡ç‰ˆ)", layout="wide")

GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
NAVER_API_KEY = st.secrets.get("API_KEY")
NAVER_SECRET_KEY = st.secrets.get("SECRET_KEY")
NAVER_CUSTOMER_ID = st.secrets.get("CUSTOMER_ID")

if not all([GEMINI_API_KEY, NAVER_API_KEY, NAVER_SECRET_KEY, NAVER_CUSTOMER_ID]):
    st.error("âš ï¸ ç¼ºå°‘ API å¯†é’¥ï¼è¯·ç¡®ä¿ Secrets ä¸­é…ç½®äº†æ‰€æœ‰å¿…éœ€çš„ Keyã€‚")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
SECRET_KEY_BYTES = NAVER_SECRET_KEY.encode("utf-8")
NAVER_API_URL = "https://api.searchad.naver.com/keywordstool"

# ==========================================
# 1. æ ¸å¿ƒæŒ‡ä»¤ä¸å‡½æ•°å®šä¹‰
# ==========================================
PROMPT_STEP_1 = """
ä½ æ˜¯ä¸€ä¸ªç²¾é€šéŸ©å›½ Coupang è¿è¥çš„ SEO ä¸“å®¶ï¼Œå“ç‰Œåä¸º LxUã€‚æ³¨æ„ï¼šä½ çš„æ•´ä¸ªè¿è¥å›¢é˜Ÿéƒ½åœ¨ä¸­å›½ï¼Œæ‰€ä»¥ä½ å¿…é¡»éµå®ˆä»¥ä¸‹æå…¶ä¸¥æ ¼çš„ã€è¯­è¨€è¾“å‡ºéš”ç¦»è§„èŒƒã€‘ï¼š
1. æ‰€æœ‰çš„â€œåˆ†æè¿‡ç¨‹â€ã€â€œç­–ç•¥è§£é‡Šâ€ã€â€œä½¿ç”¨åŸå› â€ã€â€œä¸»å›¾å»ºè®®â€ç­‰ä»»ä½•æ²Ÿé€šæè¿°æ€§è´¨çš„æ–‡å­—ï¼Œå¿…é¡» 100% ä½¿ç”¨ã€ç®€ä½“ä¸­æ–‡ã€‘ï¼ç»å¯¹ç¦æ­¢ä½¿ç”¨éŸ©æ–‡è§£é‡Šï¼
2. åªæœ‰â€œéŸ©æ–‡å…³é”®è¯æœ¬èº«â€ã€â€œéŸ©è¯­æ ‡é¢˜â€å’Œâ€œå•†å“å¥½è¯„çš„éŸ©æ–‡åŸæ–‡â€è¿™ä¸‰ä¸ªéƒ¨åˆ†å…è®¸å‡ºç°éŸ©æ–‡ï¼Œä¸”å¿…é¡»å…¨éƒ¨é™„å¸¦å¯¹åº”çš„ã€ä¸­æ–‡ç¿»è¯‘ã€‘ã€‚

--- æ ¸å¿ƒä»»åŠ¡ ---
ç¬¬ä¸€ï¼Œæˆ‘æ˜¯ä¸€ä¸ªåœ¨éŸ©å›½åšcoupangå¹³å°çš„è·¨å¢ƒç”µå•†å–å®¶ï¼Œè¿™æ˜¯æˆ‘çš„äº§å“è¯¦æƒ…é¡µï¼Œæˆ‘ç°åœ¨éœ€è¦åå°æ‰¾å‡º20ä¸ªäº§å“å…³é”®è¯è¾“å…¥åˆ°åå°ã€‚è¯·å¸®æˆ‘æ‰¾åˆ°æˆ–è€…æ¨æµ‹å‡ºè¿™äº›ç¬¦åˆæœ¬åœ°æœç´¢ä¹ æƒ¯çš„éŸ©æ–‡å…³é”®è¯ã€‚ç»¼åˆè€ƒè™‘æ¨èå•†å“ä¸­ç±»ä¼¼äº§å“çš„æ ‡é¢˜æŒ–æ˜å…³é”®è¯ï¼ˆéœ€è¦20ä¸ªåå°è®¾ç½®çš„å…³é”®è¯ï¼Œä¸åŒ…å«å“ç‰Œè¯ï¼‰ã€‚
è¾“å‡ºè¦æ±‚ï¼š
1.ä¿ç•™ç«–ç‰ˆåºå·æ’åˆ—ï¼Œå¿…é¡»å¤–åŠ çº¯ä¸­æ–‡çš„ç­–ç•¥è§£é‡Šçš„ç‰ˆæœ¬ï¼Œå¹¶å«ä¸­æ–‡ç¿»è¯‘ã€‚
2.è¿˜éœ€è¦è¾“å‡ºä¸€æ¬¾çº¯éŸ©æ–‡é€—å·éš”å¼€çš„ç‰ˆæœ¬æ–¹ä¾¿åœ¨coupangåå°å½•å…¥ã€‚

ç¬¬äºŒï¼Œæ‰¾ç²¾å‡†é•¿å°¾è¯åšä»˜è´¹æ¨å¹¿ï¼ˆéœ€è¦ç²¾å‡†æµé‡è¯ï¼ŒæŒ‰ç›¸å…³æ€§æ’åˆ—å¹¶æ‰“åˆ†1-5ï¼‰ã€‚
å¹¿å‘Šç»„ä¸€ä¸ºã€æ ¸å¿ƒå‡ºå•è¯ã€‘ã€‚
å¹¿å‘Šç»„äºŒä¸ºã€ç²¾å‡†é•¿å°¾å…³é”®è¯ã€‘ï¼ˆå°½é‡æŒ–æ˜30ä¸ªå·¦å³ï¼ŒåŒ…å«ç¼©å†™ã€è¯­åºé¢ å€’ã€åœºæ™¯è¯ã€å…³è”ç«å“ç­‰ï¼‰ã€‚
å¹¿å‘Šç»„ä¸‰ä¸ºã€é•¿å°¾æ¡æ¼ç»„å¹¿å‘Šè¯ã€‘ï¼ˆä½CPCã€è´­ä¹°æ„å‘å¼ºã€Low Trafficã€‚åŒ…å«é”™åˆ«å­—ã€ç¼©å†™ã€æ–¹è¨€ç­‰å˜ä½“ï¼‰ã€‚
è¾“å‡ºæ ¼å¼ï¼šExcelè¡¨æ ¼å½¢å¼ã€åºå· | éŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | ä¸­æ–‡ç­–ç•¥è§£é‡Š | é¢„ä¼°æµé‡(High/Medium/Low) | ç›¸å…³æ€§è¯„åˆ†ã€‘ã€‚

ç¬¬ä¸‰ï¼Œç”Ÿæˆä¸€ä¸ªé«˜ç‚¹å‡»ç‡ (High CTR) éŸ©æ–‡æ ‡é¢˜æ–¹æ¡ˆï¼šå…¬å¼ [å“ç‰Œå] + [ç›´å‡»ç—›ç‚¹å½¢å®¹è¯] + [æ ¸å¿ƒå·®å¼‚åŒ–å–ç‚¹] + [æ ¸å¿ƒå¤§è¯] + [æ ¸å¿ƒå±æ€§/æè´¨] + [åœºæ™¯/åŠŸèƒ½]ã€‚20ä¸ªå­—ä»¥å†…ï¼Œç¬¦åˆéŸ©å›½äººå¯è¯»æ€§ï¼ˆéœ€é™„å¸¦ä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚

ç¬¬å››ï¼Œæä¾›ä¸€ä¸ªäº§å“éŸ©è¯­åç§°ç”¨äºå†…éƒ¨ç®¡ç†ï¼ˆé™„å¸¦ä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚

ç¬¬äº”ï¼ŒæŒ‰ç…§äº§å“å–ç‚¹æ’°å†™5æ¡å•†å“éŸ©æ–‡å¥½è¯„ï¼Œè¯­æ³•è‡ªç„¶ï¼Œè¡¨æ ¼å½¢å¼æ’åˆ—ï¼ˆè¡¨æ ¼å¿…é¡»åŒ…å«ï¼šéŸ©æ–‡è¯„ä»·åŸæ–‡ã€çº¯ä¸­æ–‡ç¿»è¯‘ã€çº¯ä¸­æ–‡çš„ä¹°å®¶ç—›ç‚¹åˆ†æï¼‰ã€‚

ç¬¬å…­ï¼Œå°†ä¸Šè¿°ä¸‰ä¸ªå¹¿å‘Šç»„çš„æ‰€æœ‰å…³é”®è¯è¿›è¡Œå»é‡æ±‡æ€»ï¼Œå•åˆ—çºµå‘åˆ—è¡¨è¾“å‡ºè¡¨æ ¼ã€‚

ç¬¬ä¸ƒï¼ŒAI ä¸»å›¾ç”Ÿæˆå»ºè®®ï¼šåŸºäºåœºæ™¯è¯ç”¨çº¯ä¸­æ–‡å»ºè®®èƒŒæ™¯å’Œæ„å›¾ï¼Œä¸»å›¾ä¸¥ç¦å¸¦æ–‡å­—ã€‚

ã€ç¨‹åºè¯»å–ä¸“å±æŒ‡ä»¤ - æåº¦é‡è¦ã€‘ï¼š
ä¸ºäº†æ–¹ä¾¿æˆ‘çš„ç³»ç»Ÿè‡ªåŠ¨æŠ“å–ï¼Œè¯·åŠ¡å¿…å°†â€œç¬¬å…­éƒ¨åˆ†â€çš„æœ€ç»ˆå»é‡æ±‡æ€»å…³é”®è¯ï¼Œæ”¾åœ¨ä»¥ä¸‹ä¸¤ä¸ªæ ‡è®°ä¹‹é—´è¾“å‡ºï¼æ¯è¡Œåªå†™ä¸€ä¸ªéŸ©æ–‡å…³é”®è¯ï¼Œå°½é‡ä¸è¦å¸¦ä¸­æ–‡æˆ–åºå·ã€‚
[LXU_KEYWORDS_START]
(åœ¨è¿™é‡Œå¡«å…¥çº¯éŸ©æ–‡å…³é”®è¯)
[LXU_KEYWORDS_END]
"""

PROMPT_STEP_3 = """
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´å®æˆ˜ç»éªŒçš„éŸ©å›½ Coupang è·¨å¢ƒç”µå•†è¿è¥ä¸“å®¶ï¼Œç²¾é€šéŸ©è¯­è¯­ä¹‰åˆ†æã€VOCæŒ–æ˜ä»¥åŠâ€œç²¾é“ºå¿«é€Ÿæµ‹å“â€çš„é«˜ ROAS å¹¿å‘Šç­–ç•¥ã€‚æ•´ä¸ªå›¢é˜Ÿéƒ½åœ¨ä¸­å›½ï¼Œæ‰€ä»¥é™¤éŸ©æ–‡å…³é”®è¯å¤–ï¼Œæ‰€æœ‰è§£é‡Šåˆ†æå¿…é¡»ç”¨çº¯ä¸­æ–‡è¾“å‡ºã€‚

**æ ¸å¿ƒä»»åŠ¡ï¼š**
åŸºäºäº§å“è¯¦æƒ…é¡µåŸå›¾åŠä»¥ä¸‹ Naver å…³é”®è¯çœŸå®æœç´¢é‡æ•°æ®ï¼ˆCSVæ ¼å¼ï¼‰ï¼Œè¾“å‡ºç²¾å‡†å¹¿å‘Šåˆ†ç»„ã€å¦å®šè¯è¡¨ã€‚ä¸è¦å«æœ‰ LxU çš„å“ç‰Œè¯ã€‚

ã€å¸‚åœºæ•°æ®ã€‘ï¼š
{market_data}

ç¬¬ä¸€æ­¥ï¼šå…¨ç»´åº¦åˆ†æ (è§†è§‰å±æ€§è¯†åˆ«ã€ç—›ç‚¹æŒ–æ˜ã€æ’é™¤é€»è¾‘) - å¿…é¡»çº¯ä¸­æ–‡ã€‚
ç¬¬äºŒæ­¥ï¼šå…³é”®è¯æ¸…æ´—ä¸æ‰“åˆ† (ç»“åˆæµé‡ä¸ç—›ç‚¹ä¿ç•™æ ¸å¿ƒè¯å’Œæ¡æ¼è¯ï¼Œå‰”é™¤å®½æ³›è¯)ã€‚
ç¬¬ä¸‰æ­¥ï¼šè¾“å‡ºäºŒå¤§æ¨¡å—
æ¨¡å—ä¸€ï¼šä»˜è´¹å¹¿å‘ŠæŠ•æ”¾ç­–ç•¥è¡¨ (Markdownè¡¨æ ¼ï¼Œåˆ†æ ¸å¿ƒå‡ºå•è¯ã€ç²¾å‡†é•¿å°¾è¯ã€æ¡æ¼ä¸ç—›ç‚¹ç»„ï¼ŒæŒ‰æ€»æœç´¢é‡é™åºï¼Œå¸¦åºå·ã€‚éœ€åŒ…å«éŸ©æ–‡è¯ã€ä¸­æ–‡ç¿»è¯‘å’Œé¢„ä¼°æµé‡ç­–ç•¥)ã€‚
æ¨¡å—äºŒï¼šå¦å®šå…³é”®è¯åˆ—è¡¨ (çº¯ä¸­æ–‡ç®€è¿°å±è”½çš„åŸå› ï¼Œå¹¶åˆ—å‡ºå»ºè®®å±è”½çš„éŸ©æ–‡è¯)ã€‚
"""

def clean_for_api(keyword: str) -> str:
    return re.sub(r"\s+", "", keyword)

def make_signature(method: str, uri: str, timestamp: str) -> str:
    message = f"{timestamp}.{method}.{uri}".encode("utf-8")
    signature = hmac.new(SECRET_KEY_BYTES, message, hashlib.sha256).digest()
    return base64.b64encode(signature).decode("utf-8")

def normalize_count(raw):
    if isinstance(raw, int): return raw
    if isinstance(raw, str):
        s = raw.strip()
        if s.startswith("<"): return 5
        if s.startswith(">"):
            num = s[1:].strip()
            return int(num) if num.isdigit() else 0
        s = s.replace(",", "")
        if s.isdigit(): return int(s)
    return 0

def fetch_naver_data(main_keywords, pb, st_text):
    all_rows = []
    total = len(main_keywords)
    for i, mk in enumerate(main_keywords, start=1):
        st_text.text(f"ğŸ“Š æŸ¥è¯¢ä¸­ [{i}/{total}]: {mk}")
        pb.progress(i / total)
        try:
            timestamp = str(int(time.time() * 1000))
            sig = make_signature("GET", "/keywordstool", timestamp)
            headers = {"X-Timestamp": timestamp, "X-API-KEY": NAVER_API_KEY, "X-Customer": NAVER_CUSTOMER_ID, "X-Signature": sig}
            res = requests.get(NAVER_API_URL, headers=headers, params={"hintKeywords": clean_for_api(mk), "showDetail": 1})
            if res.status_code == 200:
                data = res.json()
                for item in data.get("keywordList", [])[:8]: 
                    pc = normalize_count(item.get("monthlyPcQcCnt", 0))
                    mob = normalize_count(item.get("monthlyMobileQcCnt", 0))
                    all_rows.append({"æå–ä¸»è¯": mk, "Naveræ‰©å±•è¯": item.get("relKeyword", ""), "æ€»æœç´¢é‡": pc + mob, "ç«äº‰åº¦": item.get("compIdx", "-")})
        except Exception:
            pass
        time.sleep(1)
    df = pd.DataFrame(all_rows)
    if not df.empty:
        df = df.drop_duplicates(subset=["Naveræ‰©å±•è¯"]).sort_values(by="æ€»æœç´¢é‡", ascending=False)
    return df

# ==========================================
# 2. çŠ¶æ€ä¿æŒ (Session State)
# ==========================================
if "kw_text" not in st.session_state: st.session_state.kw_text = ""
if "df_market" not in st.session_state: st.session_state.df_market = pd.DataFrame()
if "gemini_file_name" not in st.session_state: st.session_state.gemini_file_name = ""

# ==========================================
# 3. ç•Œé¢å¸ƒå±€
# ==========================================
st.title("ğŸ›¡ï¸ LxU æµ‹å“å·¥ä½œæµ (ä¸‰æ­¥æ§åˆ¶ç‰ˆ)")
file = st.file_uploader("ğŸ“¥ å…¨å±€å”¯ä¸€å…¥å£ï¼šè¯·å…ˆä¸Šä¼  PDF è¯¦æƒ…é¡µ", type=["pdf", "png", "jpg"])

tab1, tab2, tab3 = st.tabs(["ğŸ“Œ ç¬¬ä¸€æ­¥ï¼šAIæè¯", "ğŸ“ˆ ç¬¬äºŒæ­¥ï¼šæœé‡å›æµ‹", "ğŸ§  ç¬¬ä¸‰æ­¥ï¼šç»ˆæç­–ç•¥"])

# ----------------- æ ‡ç­¾é¡µ 1 -----------------
with tab1:
    st.header("1ï¸âƒ£ æå–åˆç­›å…³é”®è¯")
    if file and st.button("ğŸš€ æ‰§è¡Œç¬¬ä¸€æ­¥ï¼šAI è§†è§‰æç‚¼"):
        model = genai.GenerativeModel("gemini-2.5-flash")
        temp_path = f"temp_{file.name}"
        with open(temp_path, "wb") as f: f.write(file.getbuffer())
        
        with st.spinner("Gemini æ­£åœ¨çœ‹å›¾å†™æŠ¥å‘Š..."):
            gen_file = genai.upload_file(path=temp_path)
            while gen_file.state.name == "PROCESSING": time.sleep(2)
            st.session_state.gemini_file_name = gen_file.name 
            
            res1 = model.generate_content([gen_file, PROMPT_STEP_1])
            with st.expander("æŸ¥çœ‹ AI å®Œæ•´åŸå§‹æŠ¥å‘Š (çº¯ä¸­æ–‡è¯´æ˜)", expanded=False):
                st.write(res1.text)
                
            match = re.search(r"\[LXU_KEYWORDS_START\](.*?)\[LXU_KEYWORDS_END\]", res1.text, re.DOTALL | re.IGNORECASE)
            kw_list = []
            if match:
                raw_block = match.group(1)
                raw_block = re.sub(r'[,ï¼Œ]', '\n', raw_block)
                for line in raw_block.split('\n'):
                    clean_word = re.sub(r'[^ê°€-í£\s]', '', line).strip()
                    clean_word = re.sub(r'\s+', ' ', clean_word)
                    if clean_word and clean_word not in kw_list:
                        kw_list.append(clean_word)
            else:
                tail_text = res1.text[-800:]
                for line in tail_text.split('\n'):
                    clean_word = re.sub(r'[^ê°€-í£\s]', '', line).strip()
                    clean_word = re.sub(r'\s+', ' ', clean_word)
                    if clean_word and clean_word not in kw_list:
                        kw_list.append(clean_word)
                kw_list = kw_list[:25]
            
            st.session_state.kw_text = "\n".join(kw_list)
            st.success("âœ… æå–å®Œæˆï¼è¯·æ ¸å¯¹ä¸‹æ–¹æ–‡æœ¬æ¡†é‡Œçš„è¯ï¼Œç¡®è®¤æ— è¯¯åï¼Œç‚¹å‡»ç½‘é¡µæœ€ä¸Šæ–¹çš„ã€ğŸ“ˆ ç¬¬äºŒæ­¥ï¼šæœé‡å›æµ‹ã€‘æ ‡ç­¾é¡µã€‚")
            os.remove(temp_path)

    user_edited_kws = st.text_area("âœï¸ å³å°†ä¼ ç»™ Naver çš„çº¯éŸ©æ–‡å…³é”®è¯ (å¯æ‰‹åŠ¨åˆ æ”¹)ï¼š", value=st.session_state.kw_text, height=300, key="kw_input_area")

# ----------------- æ ‡ç­¾é¡µ 2 -----------------
with tab2:
    st.header("2ï¸âƒ£ è·å– Naver çœŸå®æ•°æ®")
    st.info("ğŸ’¡ æç¤ºï¼šè¿™é‡Œä¼šç›´æ¥è¯»å–ä½ åœ¨ç¬¬ä¸€æ­¥ç¡®è®¤å¥½çš„çº¯éŸ©æ–‡å…³é”®è¯ã€‚")
    if st.button("ğŸ“Š æ‰§è¡Œç¬¬äºŒæ­¥ï¼šå¼€å§‹æŸ¥è¯¢"):
        final_kw_list = [kw.strip() for kw in st.session_state.kw_input_area.split("\n") if kw.strip()]
        if not final_kw_list:
            st.warning("âš ï¸ å…³é”®è¯åˆ—è¡¨ä¸ºç©ºï¼Œè¯·å…ˆå›åˆ°ç¬¬ä¸€æ­¥æå–å…³é”®è¯ï¼")
        else:
            pb = st.progress(0)
            st_text = st.empty()
            df = fetch_naver_data(final_kw_list, pb, st_text)
            if not df.empty:
                st.session_state.df_market = df
                st.success("âœ… Naver æ•°æ®æŸ¥è¯¢æˆåŠŸï¼è¯·ç‚¹å‡»ç½‘é¡µæœ€ä¸Šæ–¹çš„ã€ğŸ§  ç¬¬ä¸‰æ­¥ï¼šç»ˆæç­–ç•¥ã€‘æ ‡ç­¾é¡µã€‚")
                st.dataframe(df)
            else:
                st.error("âŒ æŸ¥è¯¢å¤±è´¥ï¼ŒNaver æœªè¿”å›æœ‰æ•ˆæ•°æ®ã€‚")

# ----------------- æ ‡ç­¾é¡µ 3 -----------------
with tab3:
    st.header("3ï¸âƒ£ ç”Ÿæˆç»ˆæå¹¿å‘Šç­–ç•¥")
    if st.button("ğŸ§  æ‰§è¡Œç¬¬ä¸‰æ­¥ï¼šAI æ’å…µå¸ƒé˜µ"):
        if st.session_state.df_market.empty:
            st.warning("âš ï¸ ç¼ºå°‘ Naver æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œç¬¬äºŒæ­¥ï¼")
        elif not st.session_state.gemini_file_name:
            st.warning("âš ï¸ ç¼ºå°‘æºæ–‡ä»¶å¥æŸ„ï¼Œè¯·é‡æ–°ä»ç¬¬ä¸€æ­¥å¼€å§‹ï¼")
        else:
            with st.spinner("AI å¤§è„‘æ­£åœ¨èåˆå®¢è§‚æ•°æ®è¿›è¡Œæ·±åº¦æ¨æ¼”..."):
                model = genai.GenerativeModel("gemini-2.5-flash")
                try:
                    gen_file = genai.get_file(st.session_state.gemini_file_name)
                    market_csv = st.session_state.df_market.to_csv(index=False)
                    final_prompt = PROMPT_STEP_3.format(market_data=market_csv)
                    
                    res3 = model.generate_content([gen_file, final_prompt])
                    st.success("âœ… ç»ˆæç­–ç•¥ç”Ÿæˆå®Œæ¯•ï¼")
                    st.markdown(res3.text)
                    st.download_button("ğŸ“¥ å¯¼å‡ºç»ˆæç­–ç•¥ (TXT)", data=res3.text, file_name="LxU_ç»ˆæç­–ç•¥.txt")
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥ï¼Œå¯èƒ½æ˜¯äº‘ç«¯æ–‡ä»¶å·²è¿‡æœŸï¼Œè¯·é‡æ–°ä¸Šä¼ ã€‚é”™è¯¯ä¿¡æ¯ï¼š{e}")
