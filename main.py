import streamlit as st
import google.generativeai as genai
import pandas as pd
import time
import os
import re
import requests
import hashlib
import hmac
import base64
from google.api_core import exceptions

# ==========================================
# 0. æ ¸å¿ƒé…ç½®
# ==========================================
st.set_page_config(page_title="LxU æµ‹å“å·¥å‚ (ç»ˆæåŒä¿®ç‰ˆ)", layout="wide")

raw_keys = st.secrets.get("GEMINI_API_KEY", "")
API_KEYS = [k.strip() for k in raw_keys.split(",") if k.strip()]
NAVER_API_KEY = st.secrets.get("API_KEY")
NAVER_SECRET_KEY = st.secrets.get("SECRET_KEY")
NAVER_CUSTOMER_ID = st.secrets.get("CUSTOMER_ID")

if not API_KEYS or not NAVER_API_KEY:
    st.error("âš ï¸ å¯†é’¥é…ç½®å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ Secretsã€‚")
    st.stop()

SECRET_KEY_BYTES = NAVER_SECRET_KEY.encode("utf-8")
NAVER_API_URL = "https://api.searchad.naver.com/keywordstool"

# ==========================================
# 1. ç‹¬ç«‹ä»»åŠ¡å¼•æ“ (å½»åº•è§£å†³ HttpError æ–‡ä»¶æƒé™å†²çª)
# ==========================================
def run_gemini_task(file_path, prompt_text):
    """
    ç‹¬ç«‹å°è£…çš„ AI ä»»åŠ¡ï¼šè‡ªå·±ä¼ æ–‡ä»¶ï¼Œè‡ªå·±ç”Ÿç»“æœï¼Œè‡ªå·±åˆ æ–‡ä»¶ï¼Œå¤±è´¥è‡ªåŠ¨æ¢ Key
    """
    for i, key in enumerate(API_KEYS):
        try:
            # 1. æŒ‚è½½å½“å‰ Key
            genai.configure(api_key=key)
            
            # 2. ç”¨å½“å‰ Key ä¸Šä¼ æ–‡ä»¶
            gen_file = genai.upload_file(path=file_path)
            while gen_file.state.name == "PROCESSING":
                time.sleep(2)
                gen_file = genai.get_file(gen_file.name)
                
            # 3. æ‰§è¡Œç”Ÿæˆ
            model = genai.GenerativeModel("gemini-1.5-flash")
            response = model.generate_content([gen_file, prompt_text])
            
            # 4. é˜…åå³ç„šï¼Œé‡Šæ”¾å½“å‰ Key çš„äº‘ç«¯ç©ºé—´
            try: genai.delete_file(gen_file.name) 
            except: pass
            
            return response.text
            
        except exceptions.ResourceExhausted:
            st.warning(f"âš ï¸ ç¬¬ {i+1} ä¸ªè´¦å·é¢åº¦è€—å°½ï¼Œè‡ªåŠ¨åˆ‡æ¢å¤‡ç”¨è´¦å·...")
            continue
        except Exception as e:
            # å…œåº•ï¼šå¦‚æœç¯å¢ƒè¿˜æ˜¯å¤ªè€æŠ¥ 404ï¼Œå°è¯•è€åå­—
            try:
                model = genai.GenerativeModel("models/gemini-1.5-flash")
                res = model.generate_content([gen_file, prompt_text])
                try: genai.delete_file(gen_file.name) 
                except: pass
                return res.text
            except Exception as inner_e:
                st.warning(f"âš ï¸ ç¬¬ {i+1} ä¸ªè´¦å·å‡ºé”™: {inner_e}")
                continue
    return None

# ==========================================
# 2. æ ¸å¿ƒæŒ‡ä»¤ (ä¸¥æ ¼è¡¨æ ¼é”å®š)
# ==========================================
PROMPT_STEP_1 = """
ä½ æ˜¯ä¸€ä¸ªç²¾é€šéŸ©å›½ Coupang è¿è¥çš„ SEO ä¸“å®¶ï¼Œå“ç‰Œåä¸º LxUã€‚é™¤éŸ©æ–‡è¯å¤–ï¼Œæ‰€æœ‰åˆ†ææ–‡å­—å¿…é¡»çº¯ä¸­æ–‡ã€‚
ç¬¬ä¸€ï¼Œæ‰¾å‡º20ä¸ªç¬¦åˆéŸ©å›½ä¹ æƒ¯çš„å…³é”®è¯ã€‚
ã€å¼ºåˆ¶æ ¼å¼ã€‘ï¼šå¿…é¡»è¾“å‡ºä¸ºä¸€ä¸ª Markdown è¡¨æ ¼ï¼š| åºå· | éŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | çº¯ä¸­æ–‡ç­–ç•¥è§£é‡Š |
è¡¨æ ¼ä¸‹æ–¹æä¾›çº¯éŸ©æ–‡é€—å·éš”å¼€çš„ç‰ˆæœ¬ã€‚
ç¬¬äºŒï¼Œç”Ÿæˆå¹¿å‘Šåˆ†ç»„ã€æ ‡é¢˜ã€å¥½è¯„ï¼ˆå‡é¡»è¡¨æ ¼åŒ–ï¼‰ã€‚
ç¬¬ä¸‰ï¼Œå»é‡æ±‡æ€»å…³é”®è¯æ”¾åœ¨ [LXU_KEYWORDS_START] å’Œ [LXU_KEYWORDS_END] ä¹‹é—´ã€‚
"""

PROMPT_STEP_3 = """
åŸºäºä»¥ä¸‹ Naver æ•°æ®è¾“å‡ºç»ˆæç­–ç•¥ï¼š
{market_data}
æ‰€æœ‰åˆ†ææ–‡å­—å¿…é¡»çº¯ä¸­æ–‡ï¼Œæ‰€æœ‰å¹¿å‘Šç­–ç•¥å»ºè®®å¿…é¡»æ•´åˆæ”¾åœ¨ä¸€ä¸ªç»Ÿä¸€çš„ Markdown è¡¨æ ¼ä¸­è¾“å‡ºã€‚
"""

# ==========================================
# 3. Naver API æŸ¥é‡å¼•æ“
# ==========================================
def fetch_naver_data(main_keywords, pb, st_text):
    all_rows = []
    for i, mk in enumerate(main_keywords, start=1):
        st_text.text(f"ğŸ“Š Naver æŸ¥è¯¢ä¸­ [{i}/{len(main_keywords)}]: {mk}")
        pb.progress(i / len(main_keywords))
        try:
            ts = str(int(time.time() * 1000))
            sig = base64.b64encode(hmac.new(SECRET_KEY_BYTES, f"{ts}.GET./keywordstool".encode("utf-8"), hashlib.sha256).digest()).decode("utf-8")
            headers = {"X-Timestamp": ts, "X-API-KEY": NAVER_API_KEY, "X-Customer": NAVER_CUSTOMER_ID, "X-Signature": sig}
            res = requests.get(NAVER_API_URL, headers=headers, params={"hintKeywords": mk.replace(" ", ""), "showDetail": 1})
            if res.status_code == 200:
                for item in res.json().get("keywordList", [])[:8]:
                    pc = int(str(item.get("monthlyPcQcCnt", 0)).replace("<", "").replace(",", "")) if item.get("monthlyPcQcCnt") else 0
                    all_rows.append({"Naverè¯": item.get("relKeyword", ""), "æœç´¢é‡": pc, "AIåŸè¯": mk})
        except: pass
        time.sleep(1) 
    return pd.DataFrame(all_rows).drop_duplicates(subset=["Naverè¯"]).sort_values(by="æœç´¢é‡", ascending=False) if all_rows else pd.DataFrame()

# ==========================================
# 4. å…¨è‡ªåŠ¨å·¥ä½œæµ UI
# ==========================================
st.title("âš¡ LxU è‡ªåŠ¨åŒ–å·¥å‚ (ç»ˆæé˜²çº¿ç‰ˆ)")

file = st.file_uploader("ğŸ“¥ ä¸Šä¼ è¯¦æƒ…é¡µ", type=["pdf", "png", "jpg"])

if file and st.button("ğŸš€ å¯åŠ¨æµæ°´çº¿"):
    temp_path = f"temp_{file.name}"
    with open(temp_path, "wb") as f: f.write(file.getbuffer())
    
    with st.status("ğŸ” ç¬¬ä¸€æ­¥ï¼šAI æè¯ (ç‰©ç†éš”ç¦»æ‰§è¡Œä¸­)...", expanded=True) as s1:
        res1_text = run_gemini_task(temp_path, PROMPT_STEP_1)
        
        if res1_text:
            st.markdown(res1_text)
            kw_match = re.search(r"\[LXU_KEYWORDS_START\](.*?)\[LXU_KEYWORDS_END\]", res1_text, re.DOTALL)
            kw_list = [re.sub(r'[^ê°€-í£\s]', '', l).strip() for l in kw_match.group(1).split('\n') if l.strip()] if kw_match else []
            s1.update(label=f"âœ… ç¬¬ä¸€æ­¥å®Œæˆ", state="complete")
        else:
            st.error("âŒ ä»»åŠ¡å¤±è´¥ï¼šè´¦å·é¢åº¦è€—å°½æˆ–ç¯å¢ƒä¾æ—§ä¸å…¼å®¹ã€‚è¯·ç¡®ä¿å·²æ·»åŠ  requirements.txtï¼")
            os.remove(temp_path)
            st.stop()

    with st.status("ğŸ“Š ç¬¬äºŒæ­¥ï¼šNaver æŸ¥é‡...", expanded=True) as s2:
        pb = st.progress(0); txt = st.empty()
        df_market = fetch_naver_data(kw_list, pb, txt)
        if not df_market.empty:
            st.dataframe(df_market)
            s2.update(label=f"âœ… ç¬¬äºŒæ­¥å®Œæˆ (è¡ç”Ÿè¯ï¼š{len(df_market)})", state="complete")
        else: 
            st.error("Naver æ¥å£æœªè¿”å›æœ‰æ•ˆæ•°æ®"); os.remove(temp_path); st.stop()

    with st.status("ğŸ§  ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»ˆæå†³ç­–...", expanded=True) as s3:
        market_csv = df_market.to_csv(index=False)
        res3_text = run_gemini_task(temp_path, PROMPT_STEP_3.format(market_data=market_csv))
        
        if res3_text:
            st.markdown(res3_text)
            s3.update(label="âœ… ç¬¬ä¸‰æ­¥å®Œæˆ", state="complete")
        else:
            st.error("âŒ ç¬¬ä¸‰æ­¥ç­–ç•¥ç”Ÿæˆå¤±è´¥ã€‚")
            
    # å…¨å±€æ¸…ç†æœ¬åœ°ç¼“å­˜
    os.remove(temp_path)
