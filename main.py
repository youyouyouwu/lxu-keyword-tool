import streamlit as st
import google.generativeai as genai
import pandas as pd
import time
import os
import re
import requests
import hashlib
import hmac
import base64

# ==========================================
# 0. é¡µé¢ä¸ Secrets é…ç½®
# ==========================================
st.set_page_config(page_title="LxU æµ‹å“å·¥å‚ (ç»ˆæä¿®æ­£ç‰ˆ)", layout="wide")

GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
NAVER_API_KEY = st.secrets.get("API_KEY")
NAVER_SECRET_KEY = st.secrets.get("SECRET_KEY")
NAVER_CUSTOMER_ID = st.secrets.get("CUSTOMER_ID")

if not all([GEMINI_API_KEY, NAVER_API_KEY, NAVER_SECRET_KEY, NAVER_CUSTOMER_ID]):
    st.error("âš ï¸ å¯†é’¥æœªé…é½ï¼Œè¯·æ£€æŸ¥ Secretsã€‚")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
SECRET_KEY_BYTES = NAVER_SECRET_KEY.encode("utf-8")
NAVER_API_URL = "https://api.searchad.naver.com/keywordstool"

# ä¾§è¾¹æ æ€¥æ•‘
with st.sidebar:
    st.header("ğŸ› ï¸ ç³»ç»Ÿç»´æŠ¤")
    if st.button("ğŸ—‘ï¸ æ¸…ç†äº‘ç«¯ç§¯å‹åƒåœ¾"):
        try:
            for f in genai.list_files():
                genai.delete_file(f.name)
            st.success("æ¸…ç†æˆåŠŸï¼")
        except: st.error("æ¸…ç†å¤±è´¥æˆ–ç©ºé—´å·²ç©º")

# ==========================================
# 1. æ ¸å¿ƒæŒ‡ä»¤ (ç¬¬ä¸€æ­¥å¼ºåˆ¶è¡¨æ ¼è¾“å‡º + çº¯ä¸­æ–‡éš”ç¦»)
# ==========================================
PROMPT_STEP_1 = """
ä½ æ˜¯ä¸€ä¸ªç²¾é€šéŸ©å›½ Coupang è¿è¥çš„ SEO ä¸“å®¶ï¼Œå“ç‰Œåä¸º LxUã€‚ä½ çš„æ•´ä¸ªè¿è¥å›¢é˜Ÿéƒ½åœ¨ä¸­å›½ï¼Œè¯·éµå®ˆã€è¯­è¨€éš”ç¦»ã€‘ï¼šé™¤éŸ©æ–‡è¯å¤–ï¼Œæ‰€æœ‰åˆ†ææ–‡å­—å¿…é¡» 100% ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚

--- ä»»åŠ¡ ---
ç¬¬ä¸€ï¼Œåˆ†æè¯¦æƒ…é¡µæ‰¾å‡º20ä¸ªç¬¦åˆéŸ©å›½æœç´¢ä¹ æƒ¯çš„å…³é”®è¯ã€‚
ã€ç»å¯¹å¼ºåˆ¶æ ¼å¼ã€‘ï¼šå¿…é¡»è¾“å‡ºä¸ºä¸€ä¸ªæ ‡å‡†çš„ Markdown è¡¨æ ¼ï¼Œä¸¥ç¦ä½¿ç”¨å­å¼¹å¤´åˆ—è¡¨ã€‚
è¡¨æ ¼éª¨æ¶ï¼š| åºå· | éŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | çº¯ä¸­æ–‡ç­–ç•¥è§£é‡Š |
è¡¨æ ¼ä¸‹æ–¹è¾“å‡ºçº¯éŸ©æ–‡é€—å·éš”å¼€çš„ç‰ˆæœ¬ã€‚

ç¬¬äºŒï¼Œè¾“å‡ºå¹¿å‘Šåˆ†ç»„å»ºè®®ï¼Œå¿…é¡»ä»¥ Markdown è¡¨æ ¼æ’åˆ—ã€‚
è¡¨æ ¼éª¨æ¶ï¼š| åºå· | å¹¿å‘Šç»„åˆ†ç±» | éŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | ä¸­æ–‡ç­–ç•¥è§£é‡Š | é¢„ä¼°æµé‡ | ç›¸å…³æ€§è¯„åˆ† |

ç¬¬ä¸‰ï¼Œç”Ÿæˆé«˜ç‚¹å‡»ç‡éŸ©æ–‡æ ‡é¢˜æ–¹æ¡ˆï¼ˆé™„ä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚
ç¬¬å››ï¼Œäº§å“éŸ©è¯­ç®¡ç†åç§°ï¼ˆé™„ä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚
ç¬¬äº”ï¼Œæ’°å†™5æ¡å•†å“éŸ©æ–‡å¥½è¯„ï¼ˆå¿…é¡»è¡¨æ ¼å½¢å¼ï¼Œå«ç¿»è¯‘å’Œä¹°å®¶ç—›ç‚¹åˆ†æï¼‰ã€‚
ç¬¬å…­ï¼Œå°†æ‰€æœ‰å…³é”®è¯å»é‡æ±‡æ€»ï¼Œæ”¾åœ¨ [LXU_KEYWORDS_START] å’Œ [LXU_KEYWORDS_END] ä¹‹é—´ï¼Œæ¯è¡Œä¸€ä¸ªã€‚
ç¬¬ä¸ƒï¼ŒAI ä¸»å›¾å»ºè®®ï¼ˆçº¯ä¸­æ–‡ï¼‰ã€‚
"""

PROMPT_STEP_3 = """
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´å®æˆ˜ç»éªŒçš„éŸ©å›½ Coupang ä¸“å®¶ã€‚æ•´ä¸ªå›¢é˜Ÿéƒ½åœ¨ä¸­å›½ï¼Œè¯·ç”¨çº¯ä¸­æ–‡è¾“å‡ºåˆ†æã€‚
åŸºäºè¯¦æƒ…é¡µåŸå›¾åŠä»¥ä¸‹ Naver æ•°æ®ï¼Œè¾“å‡ºç­–ç•¥ï¼š
{market_data}

ç¬¬ä¸€æ­¥ï¼šè§†è§‰/ç—›ç‚¹åˆ†æï¼ˆçº¯ä¸­æ–‡ï¼‰ã€‚
ç¬¬äºŒæ­¥ï¼šè¾“å‡ºç»Ÿä¸€çš„ Markdown è¡¨æ ¼ï¼åŒ…å«æ‰€æœ‰å¹¿å‘Šåˆ†ç»„è¯æ±‡ã€‚
è¡¨å¤´ï¼š| åºå· | å¹¿å‘Šç»„åˆ†ç±» | éŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | æœˆæ€»æœç´¢é‡ | ç«äº‰åº¦ | æ¨èç­–ç•¥ |
ç¬¬ä¸‰æ­¥ï¼šå¦å®šå…³é”®è¯åˆ—è¡¨åŠåŸå› ï¼ˆçº¯ä¸­æ–‡ï¼‰ã€‚
"""

# ==========================================
# 2. æ ¸å¿ƒå‡½æ•° (API è°ƒç”¨)
# ==========================================
def clean_for_api(keyword: str): return re.sub(r"\s+", "", keyword)

def make_signature(method, uri, timestamp):
    message = f"{timestamp}.{method}.{uri}".encode("utf-8")
    sig = hmac.new(SECRET_KEY_BYTES, message, hashlib.sha256).digest()
    return base64.b64encode(sig).decode("utf-8")

def normalize_count(raw):
    if isinstance(raw, int): return raw
    if isinstance(raw, str):
        s = raw.strip().replace(",", "")
        if s.startswith("<"): return 5
        return int(s) if s.isdigit() else 0
    return 0

def fetch_naver_data(main_keywords, pb, st_text):
    all_rows = []
    total = len(main_keywords)
    for i, mk in enumerate(main_keywords, start=1):
        st_text.text(f"ğŸ“Š Naver æŸ¥è¯¢ä¸­ [{i}/{total}]: {mk}")
        pb.progress(i / total)
        try:
            ts = str(int(time.time() * 1000))
            headers = {"X-Timestamp": ts, "X-API-KEY": NAVER_API_KEY, "X-Customer": NAVER_CUSTOMER_ID, "X-Signature": make_signature("GET", "/keywordstool", ts)}
            res = requests.get(NAVER_API_URL, headers=headers, params={"hintKeywords": clean_for_api(mk), "showDetail": 1})
            if res.status_code == 200:
                for item in res.json().get("keywordList", [])[:8]:
                    pc = normalize_count(item.get("monthlyPcQcCnt", 0))
                    mob = normalize_count(item.get("monthlyMobileQcCnt", 0))
                    all_rows.append({"Naverè¯": item.get("relKeyword", ""), "æœç´¢é‡": pc + mob, "ç«äº‰åº¦": item.get("compIdx", "-"), "æºè‡ªAIè¯": mk})
        except: pass
        time.sleep(1)
    df = pd.DataFrame(all_rows)
    return df.drop_duplicates(subset=["Naverè¯"]).sort_values(by="æœç´¢é‡", ascending=False) if not df.empty else df

# ==========================================
# 3. è¿è¡Œå·¥ä½œæµ
# ==========================================
st.title("âš¡ LxU è‡ªåŠ¨åŒ–æµ‹å“å·¥å‚")
files = st.file_uploader("ğŸ“¥ ä¸Šä¼ è¯¦æƒ…é¡µ", type=["pdf", "png", "jpg"], accept_multiple_files=True)

if files and st.button("ğŸš€ å¯åŠ¨å…¨è‡ªåŠ¨é—­ç¯"):
    # ä½¿ç”¨é€šç”¨æ€§æœ€å¼ºçš„åç§°ï¼Œè§£å†³ 404 æŠ¥é”™
    model = genai.GenerativeModel("gemini-1.5-flash-latest")
    
    for file in files:
        st.divider()
        st.header(f"ğŸ“¦ å¤„ç†äº§å“ï¼š{file.name}")
        temp_path = f"temp_{file.name}"
        with open(temp_path, "wb") as f: f.write(file.getbuffer())
        
        with st.status("ğŸ” ç¬¬ä¸€æ­¥ï¼šAI æè¯...", expanded=True) as s1:
            try:
                gen_file = genai.upload_file(path=temp_path)
                while gen_file.state.name == "PROCESSING":
                    time.sleep(2)
                    gen_file = genai.get_file(gen_file.name)
                
                # æ‰§è¡Œ AI ç”Ÿæˆ (åŠ ä¸Šé”™è¯¯æ•è·)
                res1 = model.generate_content([gen_file, PROMPT_STEP_1])
                st.markdown(res1.text)
                
                kw_match = re.search(r"\[LXU_KEYWORDS_START\](.*?)\[LXU_KEYWORDS_END\]", res1.text, re.DOTALL | re.IGNORECASE)
                kw_list = []
                if kw_match:
                    for line in kw_match.group(1).split('\n'):
                        word = re.sub(r'[^ê°€-í£\s]', '', line).strip()
                        if word: kw_list.append(word)
                
                if kw_list: s1.update(label=f"âœ… ç¬¬ä¸€æ­¥å®Œæˆï¼Œæ•è· {len(kw_list)} è¯", state="complete")
                else: s1.update(label="âŒ æå–å¤±è´¥", state="error"); continue
            except Exception as e:
                st.error(f"AI æ•…éšœ: {e}. è¯·ç­‰å¾… 1 åˆ†é’Ÿæˆ–æ¸…ç†äº‘ç«¯ã€‚"); continue

        with st.status("ğŸ“Š ç¬¬äºŒæ­¥ï¼šNaver æŸ¥é‡...", expanded=True) as s2:
            pb = st.progress(0); txt = st.empty()
            df_market = fetch_naver_data(kw_list, pb, txt)
            if not df_market.empty:
                st.dataframe(df_market)
                s2.update(label=f"âœ… ç¬¬äºŒæ­¥å®Œæˆ (ç›®æ ‡ï¼š{len(kw_list)} -> è¡ç”Ÿï¼š{len(df_market)})", state="complete")
            else: st.error("Naver æ•°æ®ä¸ºç©º"); continue

        with st.status("ğŸ§  ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»ˆæç­–ç•¥...", expanded=True) as s3:
            market_csv = df_market.to_csv(index=False)
            res3 = model.generate_content([gen_file, PROMPT_STEP_3.format(market_data=market_csv)])
            st.markdown(res3.text)
            s3.update(label="âœ… ç¬¬ä¸‰æ­¥å®Œæˆï¼", state="complete")

        os.remove(temp_path)
        try: genai.delete_file(gen_file.name)
        except: pass
