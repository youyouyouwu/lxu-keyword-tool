import streamlit as st
import google.generativeai as genai
import pandas as pd
import time
import os
import re
import requests
import hashlib
import hmac
import base64
from google.api_core import exceptions

# ==========================================
# 0. æ ¸å¿ƒé…ç½®ä¸å¤š Key è½®æ¢å¼•æ“
# ==========================================
st.set_page_config(page_title="LxU æµ‹å“å·¥å‚ (å¤šKeyè‡ªåŠ¨åˆ‡æ¢ç‰ˆ)", layout="wide")

# è‡ªåŠ¨è§£æå¤š Key åˆ—è¡¨
raw_keys = st.secrets.get("GEMINI_API_KEY", "")
API_KEYS = [k.strip() for k in raw_keys.split(",") if k.strip()]
NAVER_API_KEY = st.secrets.get("API_KEY")
NAVER_SECRET_KEY = st.secrets.get("SECRET_KEY")
NAVER_CUSTOMER_ID = st.secrets.get("CUSTOMER_ID")

if not API_KEYS or not NAVER_API_KEY:
    st.error("âš ï¸ å¯†é’¥é…ç½®å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ Secrets æ˜¯å¦å·²æŒ‰é€—å·éš”å¼€å¡«å…¥å¤šä¸ª Keyã€‚")
    st.stop()

SECRET_KEY_BYTES = NAVER_SECRET_KEY.encode("utf-8")
NAVER_API_URL = "https://api.searchad.naver.com/keywordstool"

# --- æ™ºèƒ½åˆ‡æ¢æ‰§è¡Œå™¨ ---
def call_gemini_with_rotation(content_payload):
    """
    å¦‚æœå½“å‰ Key é¢åº¦è€—å°½ï¼Œè‡ªåŠ¨è½®è¯¢ä¸‹ä¸€ä¸ªå¯ç”¨ Key
    """
    for i, current_key in enumerate(API_KEYS):
        try:
            genai.configure(api_key=current_key)
            # é‡‡ç”¨å…¼å®¹æ€§æœ€å¼ºçš„ 1.5-flash æ¨¡å‹è·¯å¾„
            model = genai.GenerativeModel("models/gemini-1.5-flash")
            response = model.generate_content(content_payload)
            return response
        except exceptions.ResourceExhausted:
            st.warning(f"ğŸ’¡ ç³»ç»Ÿæç¤ºï¼šç¬¬ {i+1} ä¸ªè´¦å·é¢åº¦æš‚è€—å°½ï¼Œæ­£åœ¨è‡ªåŠ¨åˆ‡æ¢å¤‡ç”¨è´¦å·...")
            continue # æ¢ä¸‹ä¸€ä¸ª Key
        except Exception as e:
            st.warning(f"âš ï¸ ç¬¬ {i+1} ä¸ªè´¦å·è°ƒç”¨å‡ºé”™: {e}")
            continue
    return None

# ==========================================
# 1. æ ¸å¿ƒæŒ‡ä»¤ (ç¬¬ä¸€æ­¥å¼ºåˆ¶è¡¨æ ¼è¾“å‡º + çº¯ä¸­æ–‡éš”ç¦»)
# ==========================================
PROMPT_STEP_1 = """
ä½ æ˜¯ä¸€ä¸ªç²¾é€šéŸ©å›½ Coupang è¿è¥çš„ SEO ä¸“å®¶ï¼Œå“ç‰Œåä¸º LxUã€‚ä½ çš„å›¢é˜Ÿåœ¨ä¸­å›½ï¼Œé™¤éŸ©æ–‡è¯å¤–ï¼Œæ‰€æœ‰æ–‡å­—å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚
ç¬¬ä¸€ï¼Œæ‰¾å‡º20ä¸ªç¬¦åˆéŸ©å›½ä¹ æƒ¯çš„å…³é”®è¯ã€‚
ã€å¼ºåˆ¶æ ¼å¼ã€‘ï¼šå¿…é¡»è¾“å‡º Markdown è¡¨æ ¼ï¼š| åºå· | éŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | çº¯ä¸­æ–‡ç­–ç•¥è§£é‡Š |
è¡¨æ ¼ä¸‹æ–¹æä¾›çº¯éŸ©æ–‡é€—å·éš”å¼€çš„ç‰ˆæœ¬ã€‚
ç¬¬äºŒï¼Œç”Ÿæˆå¹¿å‘Šåˆ†ç»„ã€æ ‡é¢˜ã€å¥½è¯„ï¼ˆå‡é¡»è¡¨æ ¼åŒ–ï¼‰ã€‚
ç¬¬ä¸‰ï¼Œå»é‡æ±‡æ€»å…³é”®è¯æ”¾åœ¨ [LXU_KEYWORDS_START] å’Œ [LXU_KEYWORDS_END] ä¹‹é—´ã€‚
"""

PROMPT_STEP_3 = """
åŸºäºä»¥ä¸‹ Naver æ•°æ®è¾“å‡ºç»ˆæç­–ç•¥ï¼š
{market_data}
æ‰€æœ‰åˆ†ææ–‡å­—å¿…é¡»çº¯ä¸­æ–‡ï¼Œæ‰€æœ‰å…³é”®è¯å»ºè®®å¿…é¡»æ”¾åœ¨ä¸€ä¸ªç»Ÿä¸€çš„è¡¨æ ¼ä¸­è¾“å‡ºã€‚
"""

# Naver å‡½æ•°
def make_signature(method, uri, timestamp):
    message = f"{timestamp}.{method}.{uri}".encode("utf-8")
    sig = hmac.new(SECRET_KEY_BYTES, message, hashlib.sha256).digest()
    return base64.b64encode(sig).decode("utf-8")

def fetch_naver_data(main_keywords, pb, st_text):
    all_rows = []
    for i, mk in enumerate(main_keywords, start=1):
        st_text.text(f"ğŸ“Š Naver æŸ¥è¯¢ä¸­ [{i}/{len(main_keywords)}]: {mk}")
        pb.progress(i / len(main_keywords))
        try:
            ts = str(int(time.time() * 1000))
            headers = {"X-Timestamp": ts, "X-API-KEY": NAVER_API_KEY, "X-Customer": NAVER_CUSTOMER_ID, "X-Signature": make_signature("GET", "/keywordstool", ts)}
            res = requests.get(NAVER_API_URL, headers=headers, params={"hintKeywords": mk.replace(" ", ""), "showDetail": 1})
            if res.status_code == 200:
                for item in res.json().get("keywordList", [])[:8]:
                    pc = int(str(item.get("monthlyPcQcCnt", 0)).replace("<", "").replace(",", "")) if item.get("monthlyPcQcCnt") else 0
                    all_rows.append({"Naverè¯": item.get("relKeyword", ""), "æœç´¢é‡": pc, "AIåŸè¯": mk})
        except: pass
        time.sleep(1) # API é¢‘ç‡ä¿æŠ¤
    return pd.DataFrame(all_rows).drop_duplicates(subset=["Naverè¯"]).sort_values(by="æœç´¢é‡", ascending=False) if all_rows else pd.DataFrame()

# ==========================================
# 2. è‡ªåŠ¨åŒ–å·¥ä½œæµ
# ==========================================
st.title("âš¡ LxU è‡ªåŠ¨åŒ–å·¥å‚ (å¤šè´¦å·å†—ä½™ç‰ˆ)")
st.sidebar.info(f"å½“å‰å·²æŒ‚è½½å¤‡ç”¨ Key æ•°é‡: {len(API_KEYS)}")

file = st.file_uploader("ğŸ“¥ ä¸Šä¼ è¯¦æƒ…é¡µ (æ”¯æŒå¤š Key è‡ªåŠ¨åˆ‡åˆ†)", type=["pdf", "png", "jpg"])

if file and st.button("ğŸš€ å¯åŠ¨æµæ°´çº¿"):
    temp_path = f"temp_{file.name}"
    with open(temp_path, "wb") as f: f.write(file.getbuffer())
    
    with st.status("ğŸ” ç¬¬ä¸€æ­¥ï¼šAI æè¯ (å…¨è‡ªåŠ¨è½®è¯¢ä¸­)...", expanded=True) as s1:
        gen_file = genai.upload_file(path=temp_path)
        while gen_file.state.name == "PROCESSING":
            time.sleep(2)
            gen_file = genai.get_file(gen_file.name)
        
        # ä½¿ç”¨è‡ªåŠ¨è½®æ¢å‡½æ•°
        res1 = call_gemini_with_rotation([gen_file, PROMPT_STEP_1])
        if res1:
            st.markdown(res1.text)
            kw_match = re.search(r"\[LXU_KEYWORDS_START\](.*?)\[LXU_KEYWORDS_END\]", res1.text, re.DOTALL)
            kw_list = [re.sub(r'[^ê°€-í£\s]', '', l).strip() for l in kw_match.group(1).split('\n') if l.strip()] if kw_match else []
            s1.update(label=f"âœ… ç¬¬ä¸€æ­¥å®Œæˆ", state="complete")
        else:
            st.error("âŒ æ‰€æœ‰è´¦å·é¢åº¦å‡å·²è€—å°½ï¼Œè¯·ç¨åå†è¯•æˆ–æ–°å¢ Keyã€‚")
            st.stop()

    with st.status("ğŸ“Š ç¬¬äºŒæ­¥ï¼šNaver æŸ¥é‡...", expanded=True) as s2:
        pb = st.progress(0); txt = st.empty()
        df_market = fetch_naver_data(kw_list, pb, txt)
        if not df_market.empty:
            st.dataframe(df_market)
            s2.update(label=f"âœ… ç¬¬äºŒæ­¥å®Œæˆ (è¡ç”Ÿè¯ï¼š{len(df_market)})", state="complete")
        else: st.error("Naver æ¥å£æœªè¿”å›æœ‰æ•ˆæ•°æ®"); st.stop()

    with st.status("ğŸ§  ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»ˆæå†³ç­–...", expanded=True) as s3:
        market_csv = df_market.to_csv(index=False)
        # å†æ¬¡è°ƒç”¨è½®æ¢å‡½æ•°
        res3 = call_gemini_with_rotation([gen_file, PROMPT_STEP_3.format(market_data=market_csv)])
        if res3:
            st.markdown(res3.text)
            s3.update(label="âœ… ç¬¬ä¸‰æ­¥å®Œæˆ", state="complete")
            
    os.remove(temp_path)
    try: genai.delete_file(gen_file.name)
    except: pass
