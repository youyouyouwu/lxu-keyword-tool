import streamlit as st
import google.generativeai as genai
import pandas as pd
import time
import os
import re
import requests
import hashlib
import hmac
import base64
import concurrent.futures

# ==========================================
# 0. é¡µé¢ä¸ Secrets é…ç½®
# ==========================================
st.set_page_config(page_title="LxU æµ‹å“å·¥ä½œæµ (å›å½’åŸå‘³ç‰ˆ)", layout="wide")

GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
NAVER_API_KEY = st.secrets.get("API_KEY")
NAVER_SECRET_KEY = st.secrets.get("SECRET_KEY")
NAVER_CUSTOMER_ID = st.secrets.get("CUSTOMER_ID")

if not all([GEMINI_API_KEY, NAVER_API_KEY, NAVER_SECRET_KEY, NAVER_CUSTOMER_ID]):
    st.error("âš ï¸ ç¼ºå°‘ API å¯†é’¥ï¼è¯·ç¡®ä¿ Secrets ä¸­é…ç½®äº†æ‰€æœ‰å¿…éœ€çš„ Keyã€‚")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
SECRET_KEY_BYTES = NAVER_SECRET_KEY.encode("utf-8")
NAVER_API_URL = "https://api.searchad.naver.com/keywordstool"

# ==========================================
# 1. æ ¸å¿ƒæŒ‡ä»¤
# ==========================================
PROMPT_STEP_1 = """
ä½ æ˜¯ä¸€ä¸ªåœ¨éŸ©å›½å¸‚åœºæ‹¥æœ‰å¤šå¹´å®æˆ˜ç»éªŒçš„ç”µå•†è¿è¥ä¸“å®¶ï¼Œç†Ÿæ‚‰ Coupang ä¸ Naver SmartStore çš„æœç´¢æœºåˆ¶å’Œç”¨æˆ·ç‚¹å‡»è¡Œä¸ºã€‚ä½ çš„æ•´ä¸ªè¿è¥å›¢é˜Ÿéƒ½åœ¨ä¸­å›½ï¼Œæ‰€ä»¥ä½ å¿…é¡»éµå®ˆä»¥ä¸‹æå…¶ä¸¥æ ¼çš„ã€è¯­è¨€è¾“å‡ºéš”ç¦»è§„èŒƒã€‘ï¼š
1. æ‰€æœ‰çš„â€œåˆ†æè¿‡ç¨‹â€ã€â€œç­–ç•¥è§£é‡Šâ€ç­‰æè¿°æ€§è´¨çš„æ–‡å­—ï¼Œå¿…é¡» 100% ä½¿ç”¨ã€ç®€ä½“ä¸­æ–‡ã€‘ï¼ç»å¯¹ç¦æ­¢ä½¿ç”¨éŸ©æ–‡è§£é‡Šï¼
2. åªæœ‰â€œéŸ©æ–‡å…³é”®è¯æœ¬èº«â€ã€â€œéŸ©è¯­æ ‡é¢˜â€å’Œâ€œå•†å“å¥½è¯„çš„éŸ©æ–‡åŸæ–‡â€å…è®¸å‡ºç°éŸ©æ–‡ï¼Œä¸”å¿…é¡»å…¨éƒ¨é™„å¸¦å¯¹åº”çš„ã€ä¸­æ–‡ç¿»è¯‘ã€‘ã€‚

--- æ ¸å¿ƒä»»åŠ¡ ---
åŸºäºæˆ‘æä¾›çš„å•†å“å›¾ç‰‡ï¼Œç”Ÿæˆèƒ½å¤Ÿæé«˜ç‚¹å‡»ç‡ã€è¯­ä¹‰è‡ªç„¶ã€æœ¬åœŸåŒ–è¡¨è¾¾å¼ºã€çªå‡ºå–ç‚¹çš„å•†å“æ ‡é¢˜ï¼ŒåŒæ—¶å…¼é¡¾æœç´¢åŒ¹é…ã€‚

ã€å“ç‰Œä¸é€šç”¨è§„åˆ™ã€‘ï¼š
- å“ç‰Œåå…¨éƒ¨é»˜è®¤å›ºå®šä¸ºï¼šLxU
- ä¸¥ç¦ä½¿ç”¨å¤¸å¼ è¥é”€è¯ï¼ˆå¦‚ ìµœê³ , 1ìœ„, ì™„ë²½ ç­‰ï¼‰ã€‚
- ä¸¥ç¦ä½¿ç”¨æ–œæ  /ã€‚
- å¿…é¡»è¯­ä¹‰é€šé¡ºï¼ŒåƒçœŸå®éŸ©å›½å–å®¶å†™çš„ï¼Œé¿å…æœºæ¢°å †ç Œå…³é”®è¯ã€‚

ã€ğŸ’¡ æåº¦é‡è¦æ’ç‰ˆè¦æ±‚ï¼šä¸€é”®å¤åˆ¶åŠŸèƒ½ã€‘ï¼š
ä½ ç”Ÿæˆçš„â€œçº¯éŸ©æ–‡é€—å·éš”å¼€çš„åå°å…³é”®è¯â€ä»¥åŠâ€œçº¯éŸ©æ–‡è¯„ä»·â€ï¼Œå¿…é¡»å•ç‹¬æ”¾åœ¨ Markdown ä»£ç å—é‡Œé¢ï¼
**è­¦å‘Šï¼šä»£ç å—å¼€å¤´åªå…è®¸å†™ä¸‰ä¸ªåå¼•å· ``` ï¼Œç»å¯¹ä¸å…è®¸å‡ºç° ```text æˆ–ä»»ä½•å­—æ¯ï¼ä»£ç å—å†…åªæœ‰çº¯éŸ©æ–‡ï¼ˆå¦‚æœæ˜¯å…³é”®è¯åŠ é€—å·ï¼‰ï¼Œä¸å…è®¸æœ‰å…¶ä»–å¤šä½™è§£é‡Šï¼**

ç¬¬ä¸€éƒ¨åˆ†ï¼šCoupang ä¸“å±ä¼˜åŒ– (åè½¬åŒ–ä¸æ¸…æ™°è¡¨è¾¾)
1. æ ‡é¢˜å…¬å¼ï¼šLxU + æ ¸å¿ƒå–ç‚¹ + å…³é”®è§„æ ¼æˆ–å±æ€§ + ä½¿ç”¨åœºæ™¯æˆ–è§£å†³é—®é¢˜ç‚¹ã€‚æ ¸å¿ƒè¯å¿…é¡»æ”¾å‰é¢ã€‚
-> è¾“å‡ºå¸¦ä¸­æ–‡ç¿»è¯‘çš„æ ‡é¢˜ï¼ˆéŸ©æ–‡æ ‡é¢˜åŠ¡å¿…æ”¾åœ¨ä¸Šè¿°è¦æ±‚çš„ä»£ç å—é‡Œï¼‰ã€‚
2. æŒ–æ˜ 20 ä¸ª Coupang åå°ç²¾å‡†å…³é”®è¯ï¼ˆ2~20å­—ç¬¦ï¼‰ã€‚
-> å¿…é¡»ä»¥ Markdown è¡¨æ ¼è¾“å‡ºï¼šã€åºå· | CoupangéŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | çº¯ä¸­æ–‡ç­–ç•¥è§£é‡Šã€‘ã€‚
-> è¡¨æ ¼ä¸‹æ–¹ï¼Œå•ç‹¬æŠŠè¿™20ä¸ªçº¯éŸ©æ–‡è¯ç”¨é€—å·éš”å¼€ï¼Œå¹¶åŠ¡å¿…æ”¾åœ¨ä¸Šè¿°è¦æ±‚çš„ä»£ç å—é‡Œè¾“å‡ºã€‚

ç¬¬äºŒéƒ¨åˆ†ï¼šNaver ä¸“å±ä¼˜åŒ– (åæœç´¢è¦†ç›–ä¸æ›å…‰)
1. æ ‡é¢˜è§„åˆ™ï¼šLxU + æ ¸å¿ƒè¯ + ä¿®é¥°è¯ä¸é•¿å°¾è¯ï¼ŒåŠ å…¥æ›´å¤šç”¨æˆ·æœç´¢è¡¨è¾¾ã€‚
-> è¾“å‡ºå¸¦ä¸­æ–‡ç¿»è¯‘çš„æ ‡é¢˜ï¼ˆéŸ©æ–‡æ ‡é¢˜åŠ¡å¿…æ”¾åœ¨ä»£ç å—é‡Œï¼‰ã€‚
2. æŒ–æ˜ 20 ä¸ª Naver åå°æ‰©å±•å…³é”®è¯ï¼ˆåæœç´¢æ‰©å±•ï¼‰ã€‚
-> å¿…é¡»ä»¥ Markdown è¡¨æ ¼è¾“å‡ºï¼šã€åºå· | NaveréŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | çº¯ä¸­æ–‡ç­–ç•¥è§£é‡Šã€‘ã€‚
-> è¡¨æ ¼ä¸‹æ–¹ï¼Œå•ç‹¬æŠŠè¿™20ä¸ªçº¯éŸ©æ–‡è¯ç”¨é€—å·éš”å¼€ï¼Œå¹¶åŠ¡å¿…æ”¾åœ¨ä»£ç å—é‡Œè¾“å‡ºã€‚

ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ‰¾ç²¾å‡†é•¿å°¾è¯åšä»˜è´¹æ¨å¹¿
å¹¿å‘Šç»„ä¸€ä¸ºã€æ ¸å¿ƒå‡ºå•è¯ã€‘ï¼Œå¹¿å‘Šç»„äºŒä¸ºã€ç²¾å‡†é•¿å°¾å…³é”®è¯ã€‘ï¼Œå¹¿å‘Šç»„ä¸‰ä¸ºã€é•¿å°¾æ¡æ¼ç»„ã€‘ã€‚
è¾“å‡ºæ ¼å¼ä¸º Markdown è¡¨æ ¼ï¼šã€åºå· | å¹¿å‘Šç»„åˆ†ç±» | éŸ©æ–‡å…³é”®è¯ | ä¸­æ–‡ç¿»è¯‘ | ä¸­æ–‡ç­–ç•¥è§£é‡Š | é¢„ä¼°æµé‡ | ç›¸å…³æ€§è¯„åˆ†(1-5)ã€‘ã€‚

ç¬¬å››éƒ¨åˆ†ï¼šæä¾›ä¸€ä¸ªäº§å“éŸ©è¯­åç§°ç”¨äºå†…éƒ¨ç®¡ç†ï¼ˆé™„å¸¦ä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚

ç¬¬äº”éƒ¨åˆ†ï¼šæŒ‰ç…§äº§å“å–ç‚¹æ’°å†™10æ¡å•†å“éŸ©æ–‡å¥½è¯„ã€‚
1. å…ˆä»¥ Markdown è¡¨æ ¼å½¢å¼æ’åˆ—ï¼šã€åºå· | éŸ©æ–‡è¯„ä»·åŸæ–‡ | çº¯ä¸­æ–‡ç¿»è¯‘ | ä¹°å®¶ç—›ç‚¹åˆ†æã€‘ã€‚
2. è¡¨æ ¼ä¸‹æ–¹ï¼Œå°†è¿™10æ¡çº¯éŸ©æ–‡è¯„ä»·åŸæ–‡æŒ‰è¡Œéš”å¼€ï¼Œå•ç‹¬æ”¾åœ¨ ``` ä»£ç å—ä¸­è¾“å‡ºï¼Œæ–¹ä¾¿ä¸€é”®å¤åˆ¶ã€‚

ç¬¬å…­éƒ¨åˆ†ï¼šAI ä¸»å›¾ç”Ÿæˆå»ºè®®ï¼šåŸºäºåœºæ™¯è¯ç”¨çº¯ä¸­æ–‡å»ºè®®èƒŒæ™¯å’Œæ„å›¾ã€‚

ã€ç¨‹åºè¯»å–ä¸“å±æŒ‡ä»¤ - æåº¦é‡è¦ã€‘ï¼š
å°†ä¸Šè¿°æ‰€æœ‰ç”Ÿæˆçš„ã€éŸ©æ–‡å…³é”®è¯ã€‘è¿›è¡Œå…¨é¢å»é‡æ±‡æ€»ï¼Œå•åˆ—çºµå‘åˆ—è¡¨è¾“å‡ºï¼Œå¹¶ä¸”**å¿…é¡»æ”¾åœ¨ä»¥ä¸‹ä¸¤ä¸ªæ ‡è®°ä¹‹é—´**ï¼æ¯è¡Œåªå†™ä¸€ä¸ªéŸ©æ–‡å…³é”®è¯ï¼Œå°½é‡ä¸è¦å¸¦ä¸­æ–‡æˆ–åºå·ã€‚
[LXU_KEYWORDS_START]
(åœ¨è¿™é‡Œå¡«å…¥å»é‡åçš„çº¯éŸ©æ–‡å…³é”®è¯)
[LXU_KEYWORDS_END]
"""

# ================= ç¬¬ä¸‰æ­¥å›å½’åŸç‰ˆï¼šå®Œç¾èåˆä½ æä¾›çš„é«˜ä»·å€¼ Prompt =================
PROMPT_STEP_3 = """
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´å®æˆ˜ç»éªŒçš„éŸ©å›½ Coupang è·¨å¢ƒç”µå•†è¿è¥ä¸“å®¶ï¼Œç²¾é€šéŸ©è¯­è¯­ä¹‰åˆ†æã€VOCï¼ˆç”¨æˆ·ä¹‹å£°ï¼‰æŒ–æ˜ä»¥åŠâ€œç²¾é“ºå¿«é€Ÿæµ‹å“â€çš„é«˜ ROAS å¹¿å‘Šç­–ç•¥ã€‚æˆ‘ä»¬åšçš„éŸ©å›½ç”µå•†coupangå¹³å°ï¼Œä½†æˆ‘æ˜¯ä¸€ä¸ªä¸­å›½å–å®¶ï¼Œè¾“å‡ºæˆ‘èƒ½çœ‹æ‡‚çš„ç»“æœã€‚å…³é”®è¯ç›¸å…³å†…å®¹ä¸è¦ç¿»è¯‘è‹±æ–‡ï¼Œä¿æŒéŸ©æ–‡ï¼Œåªè¦æœ‰å¯¹åº”çš„ä¸­æ–‡ç¤ºæ„å³å¯ã€‚ç»å¯¹ä¸è¦å«æœ‰ LxU çš„å“ç‰Œè¯ï¼

ã€ä»¥ä¸‹æ˜¯å¸‚åœºæ ¸å¿ƒæœç´¢è¯åŠæ‹“å±•è¯çœŸå®æµé‡æ•°æ®ã€‘ï¼š
{market_data}

**æ ¸å¿ƒä»»åŠ¡ï¼š**
åŸºäºäº§å“è¯¦æƒ…é¡µåŸå›¾ç‰¹æ€§å’Œä¸Šè¿°æ•°æ®è¡¨ç°ï¼Œè¾“å‡ºç²¾å‡†å¹¿å‘Šåˆ†ç»„ã€å¦å®šè¯è¡¨ã€‚

**ç¬¬ä¸€æ­¥ï¼šå…¨ç»´åº¦åˆ†æ (Deep Analysis)**
1. è§†è§‰ä¸å±æ€§è¯†åˆ«ï¼šåˆ†æè¯¦æƒ…é¡µä¿¡æ¯ï¼Œé”å®šæ ¸å¿ƒå±æ€§ï¼ˆæè´¨ã€å½¢çŠ¶ã€åŠŸèƒ½ã€åœºæ™¯ï¼‰ã€‚
2. ç—›ç‚¹æŒ–æ˜ï¼ˆè‹¥æœ‰è¯„è®ºï¼‰ï¼šä»ç«å“å·®è¯„ä¸­æç‚¼ç”¨æˆ·ç—›ç‚¹ï¼ˆå¦‚ï¼šå™ªéŸ³å¤§ã€æ˜“ç”Ÿé”ˆï¼‰ã€‚
3. æ’é™¤é€»è¾‘å»ºç«‹ï¼šæ˜ç¡®â€œç»å¯¹ä¸ç›¸å…³â€çš„å±æ€§ï¼ˆå¦‚ï¼šäº§å“æ˜¯å¡‘æ–™ï¼Œæ’é™¤â€œä¸é”ˆé’¢â€ï¼‰ã€‚

**ç¬¬äºŒæ­¥ï¼šå…³é”®è¯æ¸…æ´—ä¸æ‰“åˆ† (Filtering & Scoring)**
åŸºäºæˆ‘æä¾›çš„æ•°æ®åˆ—è¡¨ï¼ˆç‰¹åˆ«æ˜¯ç¬¬ä¸€æ­¥æç‚¼çš„æºå¤´è¯ï¼‰ï¼Œè¿›è¡Œä¸¥æ ¼ç­›é€‰ï¼š
1. ç›¸å…³æ€§æ‰“åˆ† (1-5åˆ†)ï¼š
   * 1-2åˆ† (ä¿ç•™)ï¼šæ ¸å¿ƒè¯åŠç²¾å‡†é•¿å°¾è¯ã€‚
   * 3åˆ† (ä¿ç•™)ï¼šå¼ºå…³è”åœºæ™¯æˆ–ç«å“è¯ï¼ˆå¯ç”¨äºæ¡æ¼ï¼‰ã€‚
   * 4-5åˆ† (å‰”é™¤/å¦å®š)ï¼šå®½æ³›å¤§è¯æˆ–å±æ€§é”™è¯¯çš„è¯ã€‚
2. æµé‡ä¸ç—›ç‚¹åŠ æƒï¼š
   * ä¼˜å…ˆä¿ç•™èƒ½è§£å†³â€œç«å“ç—›ç‚¹â€çš„è¯ã€‚
   * å‚è€ƒâ€œæ€»æœç´¢é‡â€ï¼Œä¿ç•™è™½ç„¶æµé‡å°ä½†æç²¾å‡†çš„é•¿å°¾è¯ã€‚

**ç¬¬ä¸‰æ­¥ï¼šè¾“å‡ºäºŒå¤§æ¨¡å— (Output Modules)**

**æ¨¡å—ä¸€ï¼šä»˜è´¹å¹¿å‘ŠæŠ•æ”¾ç­–ç•¥è¡¨**
è¯·ä»¥ Markdown è¡¨æ ¼è¾“å‡ºï¼Œ**ç›´æ¥å¡«å†™çœŸå®æ•°æ®ï¼Œç»ä¸å…è®¸è¾“å‡ºçœç•¥å·æˆ–è™šçº¿æ’ç‰ˆï¼**
è¡¨å¤´ä¸¥æ ¼å›ºå®šä¸ºï¼šã€åºå· | å¹¿å‘Šç»„åˆ†ç±» | ç›¸å…³æ€§è¯„åˆ† | éŸ©æ–‡å…³é”®è¯ | æœˆæ€»æœç´¢é‡ | ä¸­æ–‡ç¿»è¯‘ | ç«äº‰åº¦ | æ¨èç­–ç•¥ä¸è¯´æ˜ã€‘

* **å¹¿å‘Šç»„åˆ†ç±»ï¼ˆå¿…é¡»åŒ…å«ä»¥ä¸‹ä¸‰ç±»ï¼‰ï¼š**
   * ã€æ ¸å¿ƒå‡ºå•è¯ã€‘ï¼šæµé‡è¾ƒå¤§ï¼Œå®Œå…¨åŒ¹é…ã€‚
   * ã€ç²¾å‡†é•¿å°¾è¯ã€‘ï¼šæ ¸å¿ƒè¯+å…·ä½“å±æ€§ã€‚
   * ã€æ¡æ¼ä¸ç—›ç‚¹ç»„ã€‘ï¼šé”™åˆ«å­—ã€å€’åºã€æ–¹è¨€ã€åœºæ™¯è¯ã€ç«å“è¯ã€‚
* **æ’åºè§„åˆ™ï¼š** æŒ‰åˆ†ç±»åˆ¶ä½œä¸‰ç»„å…³é”®è¯ç»“æœåˆ—è¡¨ã€‚åœ¨åŒä¸€ä¸ªåˆ†ç±»å†…éƒ¨ï¼ŒæŒ‰â€œæœˆæ€»æœç´¢é‡â€ä»é«˜åˆ°ä½æ’åˆ—ã€‚
* **æ•°é‡è¦æ±‚ï¼š** ä¿è¯å‡†ç¡®çš„æƒ…å†µä¸‹å°½é‡ä¿è¯å…³é”®è¯æ•°é‡ï¼Œä¸è¦é—æ¼æå“è¯æ±‡ã€‚
* **æ ¼å¼è¦æ±‚ï¼š** å…³é”®è¯åé¢ä¸éœ€è¦å¸¦å‡ºå¤„çš„å°æ ‡å¿—ï¼ˆä¾‹å¦‚ [1] ç­‰ï¼‰ã€‚æ€»æœç´¢é‡åˆ—æ— æ•°æ®åˆ™é¢„ä¼°ã€‚

**æ¨¡å—äºŒï¼šå¦å®šå…³é”®è¯åˆ—è¡¨ (Negative Keywords)**
*ç”¨äºå¹¿å‘Šåå°å±è”½ï¼Œé˜²æ­¢æ— æ•ˆçƒ§é’±ã€‚*
* **å»ºè®®å±è”½çš„è¯ï¼š** `[è¯1], [è¯2], [è¯3]...` (åˆ—å‡º4-5åˆ†çš„é”™è¯¯å±æ€§è¯)
* **å±è”½åŸå› ï¼š** [ç®€è¿°ï¼Œä¾‹å¦‚ï¼šæè´¨ä¸ç¬¦ï¼ˆæˆ‘æ˜¯å¡‘æ–™ï¼Œè¯æ˜¯é‡‘å±ï¼‰ã€åœºæ™¯é”™è¯¯ç­‰]
"""

# ==========================================
# 2. Naver æ•°æ®æŠ“å–å‡½æ•° (å¹¶å‘æé€Ÿç‰ˆ)
# ==========================================
def clean_for_api(keyword: str) -> str:
    return re.sub(r"\s+", "", keyword)

def make_signature(method: str, uri: str, timestamp: str) -> str:
    message = f"{timestamp}.{method}.{uri}".encode("utf-8")
    signature = hmac.new(SECRET_KEY_BYTES, message, hashlib.sha256).digest()
    return base64.b64encode(signature).decode("utf-8")

def normalize_count(raw):
    if isinstance(raw, int): return raw
    if isinstance(raw, str):
        s = raw.strip()
        if s.startswith("<"): return 5
        if s.startswith(">"):
            num = s[1:].strip()
            return int(num) if num.isdigit() else 0
        s = s.replace(",", "")
        if s.isdigit(): return int(s)
    return 0

def fetch_naver_data(main_keywords, pb, st_text):
    all_rows = []
    total = len(main_keywords)

    def fetch_single(mk):
        rows = []
        try:
            timestamp = str(int(time.time() * 1000))
            sig = make_signature("GET", "/keywordstool", timestamp)
            headers = {"X-Timestamp": timestamp, "X-API-KEY": NAVER_API_KEY, "X-Customer": NAVER_CUSTOMER_ID, "X-Signature": sig}
            res = requests.get(NAVER_API_URL, headers=headers, params={"hintKeywords": clean_for_api(mk), "showDetail": 1}, timeout=8)
            if res.status_code == 200:
                data = res.json()
                for item in data.get("keywordList", []): 
                    pc = normalize_count(item.get("monthlyPcQcCnt", 0))
                    mob = normalize_count(item.get("monthlyMobileQcCnt", 0))
                    rows.append({
                        "Naverå®é™…æœç´¢è¯": item.get("relKeyword", ""),
                        "æœˆæ€»æœç´¢é‡": pc + mob,
                        "ç«äº‰åº¦": item.get("compIdx", "-"),
                        "AIæº¯æº(åŸè¯)": mk
                    })
        except Exception:
            pass
        return rows

    completed = 0
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_mk = {executor.submit(fetch_single, mk): mk for mk in main_keywords}
        for future in concurrent.futures.as_completed(future_to_mk):
            mk = future_to_mk[future]
            completed += 1
            st_text.text(f"ğŸ“Š Naver æé€Ÿå¹¶å‘æ‹“è¯ä¸­ [{completed}/{total}]: {mk}")
            pb.progress(completed / total)
            try:
                all_rows.extend(future.result())
            except Exception:
                pass
            time.sleep(0.05) 
            
    df = pd.DataFrame(all_rows)
    if not df.empty:
        df = df.drop_duplicates(subset=["Naverå®é™…æœç´¢è¯"]).sort_values(by="æœˆæ€»æœç´¢é‡", ascending=False)
    return df

# ==========================================
# 3. ä¸» UI ä¸å…¨è‡ªåŠ¨å·¥ä½œæµ
# ==========================================
st.title("âš¡ LxU è‡ªåŠ¨åŒ–æµ‹å“å·¥å‚ (å›å½’åŸå‘³ç¨³å®šç‰ˆ)")
st.info("ğŸ’¡ æç¤ºï¼šè¿è¡Œä¸­å¦‚éœ€ç´§æ€¥ç»ˆæ­¢ï¼Œè¯·ç‚¹å‡»é¡µé¢å³ä¸Šè§’è‡ªå¸¦çš„åœ†å½¢ Stop æŒ‰é’®ã€‚")

# æ¸…ç†ç¼“å­˜æŒ‰é’®
if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç†äº‘ç«¯åƒåœ¾æ–‡ä»¶"):
    try:
        count = 0
        for f in genai.list_files():
            genai.delete_file(f.name)
            count += 1
        st.sidebar.success(f"æ¸…ç†äº† {count} ä¸ªç¼“å­˜æ–‡ä»¶ï¼")
    except Exception as e:
        st.sidebar.error(f"æ¸…ç†å¤±è´¥: {e}")

files = st.file_uploader("ğŸ“¥ è¯·ä¸Šä¼ äº§å“è¯¦æƒ…é¡µ (å¼ºçƒˆå»ºè®®æˆªå›¾ï¼Œä¿æŒåœ¨2MBå†…)", type=["pdf", "png", "jpg", "jpeg"], accept_multiple_files=True)

if files and st.button("ğŸš€ å¯åŠ¨å…¨è‡ªåŠ¨é—­ç¯", use_container_width=True):
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    for file in files:
        st.divider()
        st.header(f"ğŸ“¦ æ­£åœ¨è‡ªåŠ¨å¤„ç†äº§å“ï¼š{file.name}")
        temp_path = f"temp_{file.name}"
        with open(temp_path, "wb") as f: f.write(file.getbuffer())
        
        # ------------------ ç¬¬ä¸€æ­¥ï¼šè‡ªåŠ¨è¯†å›¾ä¸æå– ------------------
        with st.status("ğŸ” ç¬¬ä¸€æ­¥ï¼šAI è§†è§‰æç‚¼ä¸æœ¬åœ°åŒ–åˆ†æ...", expanded=True) as s1:
            try:
                gen_file = genai.upload_file(path=temp_path)
                while gen_file.state.name == "PROCESSING":
                    time.sleep(2)
                    gen_file = genai.get_file(gen_file.name)
                
                res1 = model.generate_content([gen_file, PROMPT_STEP_1])
                with st.expander("ğŸ‘‰ æŸ¥çœ‹ç¬¬ä¸€æ­¥å®Œæ•´æŠ¥å‘Š (å·²å¼ºåˆ¶çº¯ä¸­æ–‡éš”ç¦»)", expanded=False):
                    st.write(res1.text)
                
                # å¼ºåŒ–ç‰ˆéŸ©æ–‡é•¿å°¾è¯æå–ï¼ˆä¿ç•™ç©ºæ ¼ï¼‰
                match = re.search(r"\[LXU_KEYWORDS_START\](.*?)\[LXU_KEYWORDS_END\]", res1.text, re.DOTALL | re.IGNORECASE)
                kw_list = []
                if match:
                    raw_block = match.group(1)
                    raw_block = re.sub(r'[,ï¼Œ]', '\n', raw_block)
                    for line in raw_block.split('\n'):
                        clean_word = re.sub(r'[^ê°€-í£\s]', '', line).strip()
                        clean_word = re.sub(r'\s+', ' ', clean_word)
                        if clean_word and clean_word not in kw_list:
                            kw_list.append(clean_word)
                else:
                    tail_text = res1.text[-800:]
                    for line in tail_text.split('\n'):
                        clean_word = re.sub(r'[^ê°€-í£\s]', '', line).strip()
                        clean_word = re.sub(r'\s+', ' ', clean_word)
                        if clean_word and clean_word not in kw_list:
                            kw_list.append(clean_word)
                    kw_list = kw_list[:25]
                
                if kw_list:
                    s1.update(label=f"âœ… ç¬¬ä¸€æ­¥å®Œæˆï¼æˆåŠŸæˆªè· {len(kw_list)} ä¸ªçº¯æ­£éŸ©æ–‡è¯ç»„", state="complete")
                else:
                    s1.update(label="âŒ ç¬¬ä¸€æ­¥æå–å¤±è´¥ï¼Œæœªèƒ½æ‰¾åˆ°éŸ©æ–‡", state="error")
                    continue 
            except Exception as e:
                s1.update(label=f"âŒ AI è¯·æ±‚å¤±è´¥: {e}", state="error")
                st.error("è¯·æ£€æŸ¥é¢åº¦æ˜¯å¦è€—å°½ï¼Œæˆ–ç‚¹å‡»å·¦ä¾§æ¸…ç†äº‘ç«¯ç¼“å­˜ã€‚")
                continue

        # ------------------ ç¬¬äºŒæ­¥ï¼šè‡ªåŠ¨è§¦å‘ Naver æµé‡å›æµ‹ ------------------
        with st.status("ğŸ“Š ç¬¬äºŒæ­¥ï¼šè¿æ¥ Naver è·å–çœŸå®æœç´¢æ•°æ® (è‡ªåŠ¨è·³è½¬)...", expanded=True) as s2:
            pb = st.progress(0)
            status_txt = st.empty()
            
            df_market = fetch_naver_data(kw_list, pb, status_txt)
            
            if not df_market.empty:
                st.dataframe(df_market)
                target_count = len(kw_list)
                derived_count = len(df_market)
                s2.update(label=f"âœ… ç¬¬äºŒæ­¥å®Œæˆï¼å·²è·å–æœ€æ–°éŸ©å›½å¸‚åœºå®¢è§‚æ•°æ® (ç›®æ ‡è¯ï¼š{target_count} ä¸ª â¡ï¸ è¡ç”Ÿè¯ï¼š{derived_count} ä¸ª)", state="complete")
            else:
                s2.update(label="âŒ ç¬¬äºŒæ­¥å¤±è´¥ï¼ŒNaver æœªè¿”å›æœ‰æ•ˆæ•°æ®", state="error")
                continue 

        # ------------------ ç¬¬ä¸‰æ­¥ï¼šè‡ªåŠ¨è§¦å‘ç»ˆæç­–ç•¥æ¨æ¼” ------------------
        with st.status("ğŸ§  ç¬¬ä¸‰æ­¥ï¼šä¸»å®¢è§‚æ•°æ®èåˆï¼Œç”Ÿæˆç»ˆæç­–ç•¥ (è‡ªåŠ¨è·³è½¬)...", expanded=True) as s3:
            try:
                # ä¿ç•™åŸè¯ï¼Œæå°–æ‹“å±•è¯
                seed_df = df_market[df_market["Naverå®é™…æœç´¢è¯"].isin(kw_list)]
                expanded_df = df_market[~df_market["Naverå®é™…æœç´¢è¯"].isin(kw_list)].head(250)
                
                final_df = pd.concat([seed_df, expanded_df]).drop_duplicates(subset=["Naverå®é™…æœç´¢è¯"]).sort_values(by="æœˆæ€»æœç´¢é‡", ascending=False)
                
                market_csv = final_df.to_csv(index=False)
                final_prompt = PROMPT_STEP_3.format(market_data=market_csv)
                
                res3 = model.generate_content([gen_file, final_prompt])
                st.markdown("### ğŸ† LxU ç»ˆææµ‹å“ç­–ç•¥æŠ¥å‘Š")
                st.success(res3.text)
                
                s3.update(label="âœ… ç¬¬ä¸‰æ­¥å®Œæˆï¼ç»ˆææ’å…µå¸ƒé˜µå·²ç”Ÿæˆ", state="complete")
            except Exception as e:
                s3.update(label=f"âŒ ç¬¬ä¸‰æ­¥å¤±è´¥: {e}", state="error")

        # ------------------ æ”¶å°¾ä¸å¯¼å‡º ------------------
        os.remove(temp_path)
        try:
            genai.delete_file(gen_file.name)
        except:
            pass
            
        try:
            final_report = f"ã€LxU äº§å“æµ‹å“å…¨æ™¯æŠ¥å‘Šï¼š{file.name}ã€‘\n\n" + "="*40 + "\n[ç¬¬ä¸€æ­¥ï¼šAI è§†è§‰æç‚¼ (çº¯ä¸­æ–‡)]\n" + res1.text + "\n\n" + "="*40 + "\n[ç¬¬äºŒæ­¥ï¼šNaver å®¢è§‚æœç´¢é‡ (ç²¾ç‚¼åˆé›†)]\n" + market_csv + "\n\n" + "="*40 + "\n[ç¬¬ä¸‰æ­¥ï¼šç»ˆæç­–ç•¥ä¸å¹¿å‘Šåˆ†ç»„]\n" + res3.text
            
            st.download_button(
                label=f"ğŸ“¥ ä¸€é”®ä¸‹è½½ {file.name} å®Œæ•´æµ‹å“æŠ¥å‘Š (TXT)", 
                data=final_report, 
                file_name=f"LxU_è‡ªåŠ¨æµ‹å“å…¨è®°å½•_{file.name}.txt"
            )
        except:
            pass
